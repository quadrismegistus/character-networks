{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenerateFictionalSocialNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "deepnote_execution_queue": [
      {
        "cellId": "00022-ff1162c3-3948-446c-acce-872fcf60ab66",
        "msgId": "73eb9e42-25ad-494d-8c03-023ab23dea98",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00034-b9ad6142-6563-407b-8ad3-a5876477fb26",
        "msgId": "3b9245d5-400d-4a53-9f69-d444142a93bf",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00035-cdd7ccb4-7296-4719-84d3-472673cdc443",
        "msgId": "75989d45-0e9b-4593-8c10-1686e0c373e9",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00021-179cb35d-4648-4efe-b6fd-876394c1c59b",
        "msgId": "1f814d28-4415-499c-a5cd-a6e4d9ac736a",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00021-d2051519-3a82-404d-a7e5-14b9436441f5",
        "msgId": "a6e662db-c95a-47fa-8d8a-2654d9556ead",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00037-b3aca305-2ed6-4d42-bc87-876a8d26cf36",
        "msgId": "623407f1-3b90-4d5c-a810-1a26cce986eb",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00042-a368ff89-64fc-446c-ac88-4d18dbb9f670",
        "msgId": "f0d9a721-5c91-4fe8-bb23-b80f61da596f",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00043-3339a235-3919-4caf-99cc-1a82002c8cfd",
        "msgId": "b45ca3e1-fae9-427c-8ef4-97e14b9372b8",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00044-ffe3f92e-1831-4737-819c-594d7f266bbf",
        "msgId": "e5ed3a8a-8a14-43fb-9b36-14fbf7b1ef1a",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00045-8f2dd7bd-d30d-4761-af59-69d51830b25f",
        "msgId": "62e963bc-c939-4c56-80fb-d2c4bdb06c16",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00047-2df2d7bf-fb80-4929-9343-b0c6d00b3f9c",
        "msgId": "43d8f6ce-99ff-4fba-8e2c-f8957e42728d",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00029-9d653298-4df7-47ba-83ff-6493fbe0abcf",
        "msgId": "8b63bf8c-5095-4f62-b68f-b2fdb49e9386",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00031-56f64996-c2fc-4164-a0ec-49aed297359e",
        "msgId": "faace634-b48e-474c-8663-fc377b408b9a",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00050-5274092a-6201-46a3-bfb4-eb67bd65bd31",
        "msgId": "eba35fd2-6058-4ba0-96e3-6b207ee8551d",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00051-073607cb-b12a-4873-8b2d-10354f94a5b2",
        "msgId": "a8e38a75-d9e4-4c0e-97d9-b3c40eca049b",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00052-27236b40-a756-4940-bc7e-477dfebe1af7",
        "msgId": "d1fe4d10-9b6d-439b-a0e5-ed81632fbcde",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00053-23a8a9d7-bdad-41c7-96b8-fe50809a1f59",
        "msgId": "57cf6317-7164-4143-bcf1-78dbaceaa44b",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00037-60c48190-d1e0-4b63-9a2e-3c80a1fe8eaf",
        "msgId": "a16156b7-a1d1-4162-b3c4-be79e2903043",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00054-1bfcafff-7c9a-4153-8b83-31aa3f70993b",
        "msgId": "91327988-771f-4446-b125-3dd63a96549a",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00040-fca1c1e9-1fbe-4e41-b1e9-ac75fc1e4bb9",
        "msgId": "3b31a6b1-20b1-4c50-9dcb-162201ee2951",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00037-5cf01f7b-8451-4115-bccf-a00e972fd2d0",
        "msgId": "9d80a55c-385c-4a31-9bcf-b455f32bb92e",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00056-44d9d19f-8eee-433a-b143-bc2853ec1e0f",
        "msgId": "60dc4d9d-b3cd-4911-8906-07a8f297ef39",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00057-ce693ca1-3059-4fc3-bf1c-8729c5e08ec7",
        "msgId": "fc3a255d-8b69-429b-8000-3a5a20f95a23",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00042-7bf65c2b-1cb9-4580-804f-d75e8016d3b1",
        "msgId": "a886f6d8-fdd8-49a7-aca2-9bf437b42968",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      }
    ],
    "deepnote_notebook_id": "54fb2d49-2b86-41dc-a662-7cd8d1ba9b3e",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0abe26c102604efd9f94fc678a383cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_25e5eea4157d483b96b84aa5acf9e0c8",
            "_dom_classes": [],
            "description": "Upload text",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_8c845acb004e4209a5aeedcf27a8e516",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "25e5eea4157d483b96b84aa5acf9e0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c845acb004e4209a5aeedcf27a8e516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa84fd50f9724bd7bcb0cfb9b46994e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "state": {
            "_view_name": "ButtonView",
            "style": "IPY_MODEL_45c3045c5e0a49d0adf04a7df701c1de",
            "_dom_classes": [],
            "description": "Delete file",
            "_model_name": "ButtonModel",
            "button_style": "",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "tooltip": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "layout": "IPY_MODEL_55588c53cc79408d84d0db7b55d37a31",
            "_model_module": "@jupyter-widgets/controls",
            "icon": ""
          }
        },
        "45c3045c5e0a49d0adf04a7df701c1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ButtonStyleModel",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "button_color": null,
            "font_weight": "",
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55588c53cc79408d84d0db7b55d37a31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quadrismegistus/character-networks/blob/main/GenerateFictionalSocialNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpmp2cCY6PuW"
      },
      "source": [
        "# **Powerloom**: Visualizing Character Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agqnBkrz6Pub"
      },
      "source": [
        "### 🏃‍♀️ Starting up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "kCJ3UuDHZfO-",
        "outputId": "933964d5-422d-41d6-ce87-4ac138f8651d",
        "colab": {
          "resources": {
            "http://localhost:8080/images/logo.jpg": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "0abe26c102604efd9f94fc678a383cab",
            "25e5eea4157d483b96b84aa5acf9e0c8",
            "8c845acb004e4209a5aeedcf27a8e516",
            "fa84fd50f9724bd7bcb0cfb9b46994e8",
            "45c3045c5e0a49d0adf04a7df701c1de",
            "55588c53cc79408d84d0db7b55d37a31"
          ]
        }
      },
      "source": [
        "#@title 📚 Choose a book to analyze\n",
        "#@markdown Enter the title of a book, along with a URL to a text file. To find a URL, search:\n",
        "#@markdown * [Project Gutenberg](https://gutenberg.org) for out of copyright texts\n",
        "#@markdown * [Z-lib](https://gutenberg.org) for in-copyright texts\n",
        "\n",
        "title = \"Overstory\" #@param {type:\"string\"}\n",
        "url = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "#### Initial initial imports and settings\n",
        "import os,sys\n",
        "from google.colab import drive,files\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import Markdown, display, Javascript\n",
        "# nicer print func\n",
        "def printm(x): display(Markdown(x))\n",
        "# elementary dirs\n",
        "PATH_ROOT='/content'\n",
        "PATH_LIB=os.path.join(PATH_ROOT,'lib')\n",
        "PATH_TMP=os.path.join(PATH_ROOT,'tmp')\n",
        "PATH_TMP_UPLOAD_FN_PRE=os.path.join(PATH_TMP,'uploaded_text')\n",
        "PATH_TOOLS=os.path.join('/content','tools')\n",
        "PATH_NOVELS=os.path.join(PATH_ROOT,'texts')\n",
        "PATH_TO_BOOKNLP=os.path.join(PATH_TOOLS,'book-nlp')\n",
        "if not os.path.exists(PATH_ROOT): os.makedirs(PATH_ROOT)\n",
        "if not os.path.exists(PATH_LIB): os.makedirs(PATH_LIB)\n",
        "if not os.path.exists(PATH_TMP): os.makedirs(PATH_TMP)\n",
        "# add lib to python path\n",
        "if not PATH_LIB in sys.path: sys.path.insert(0,PATH_LIB)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# offer button as well\n",
        "def upload_f(x,tmpfnpre=PATH_TMP_UPLOAD_FN_PRE):\n",
        "    from google.colab import files\n",
        "    res = files.upload()\n",
        "    fn=list(res.keys())[0]\n",
        "    if fn:\n",
        "        delete_f(None)\n",
        "        fnpre,fnext=os.path.splitext(fn)\n",
        "        tmpfn=tmpfnpre+fnext\n",
        "        !mv \"$fn\" \"$tmpfn\"\n",
        "        printm(f'* Moving to: {tmpfn}')\n",
        "    Javascript('Jupyter.notebook.execute_cell_and_select_below()')\n",
        "\n",
        "def get_uploaded_fn():\n",
        "    tmp_fns=os.listdir(PATH_TMP)\n",
        "    matches=[tmp_fn for tmp_fn in tmp_fns if tmp_fn.startswith(os.path.basename(PATH_TMP_UPLOAD_FN_PRE))]\n",
        "    if matches:\n",
        "        match=matches[0]\n",
        "        matchpath=os.path.join(PATH_TMP,match)\n",
        "        return matchpath\n",
        "\n",
        "def delete_f(x):\n",
        "    if get_uploaded_fn():# and os.path.exists(matchpath):\n",
        "        fn=get_uploaded_fn()\n",
        "        os.remove(get_uploaded_fn())\n",
        "        printm(f'* Deleted: {fn}')\n",
        "    Javascript('Jupyter.notebook.execute_cell_and_select_below()')\n",
        "\n",
        "printm('### Alternatively to a URL, you can upload a file (txt, epub, pdf, docx, ...)')\n",
        "\n",
        "ubutton = widgets.Button(description=\"Upload text\")\n",
        "ubutton.on_click(upload_f)\n",
        "display(ubutton)\n",
        "\n",
        "# is uploaded file\n",
        "if get_uploaded_fn():\n",
        "    printm(f'Currently using uploaded file: {os.path.basename(get_uploaded_fn())}')\n",
        "    delbutton = widgets.Button(description=\"Delete file\")\n",
        "    delbutton.on_click(delete_f)\n",
        "    display(delbutton)\n",
        "\n",
        "\n",
        "printm('### Checking input')\n",
        "# Load widget code\n",
        "# Valid input?\n",
        "class InvalidInput(Exception):\n",
        "    def _render_traceback_(self): pass\n",
        "NOVEL_URL=url\n",
        "NOVEL_TITLE_NICE=title.strip()\n",
        "NOVEL_TITLE=NOVEL_TITLE_NICE.title().replace(' ','')\n",
        "if not NOVEL_TITLE:\n",
        "    print('Type a title in the box above')\n",
        "    raise InvalidInput\n",
        "else:\n",
        "    printm(f'* Using title: **{NOVEL_TITLE_NICE}**')\n",
        "    printm(f'* Using filename: **{NOVEL_TITLE}**')\n",
        "\n",
        "\n",
        "\n",
        "# get txt\n",
        "### getting text using code from a gist\n",
        "!pip install bs4 kitchen wget fulltext epub-conversion pymupdf requests xml_cleaner html2text -q -q\n",
        "import urllib.request\n",
        "gisturl='https://gist.githubusercontent.com/quadrismegistus/f76c2ffcccedc496a638ca430b6851ab/raw/ede9744a01adc324a6223b924789f1553853f91c/brute_txt.py'\n",
        "ofnbrute=os.path.join(PATH_LIB,'brute_txt.py')\n",
        "if not os.path.exists(ofnbrute):\n",
        "    urllib.request.urlretrieve(gisturl,ofnbrute)\n",
        "from brute_txt import brute\n",
        "\n",
        "def get_novel_txt():\n",
        "    NOVEL_TXT=''\n",
        "    # is uploaded file?\n",
        "    if get_uploaded_fn():\n",
        "        printm(f'* Loading text from uploaded file: {get_uploaded_fn()}')\n",
        "        NOVEL_TXT=brute(get_uploaded_fn())\n",
        "    elif url:\n",
        "        printm(f'* Loading text from URL: {url}')\n",
        "        NOVEL_TXT=brute(url)\n",
        "    else:\n",
        "        printm('No uploaded file nor URL to file')\n",
        "        raise InvalidInput\n",
        "    # save text\n",
        "    if not NOVEL_TXT:\n",
        "        printm('Empty text')\n",
        "        raise InvalidInput\n",
        "    else:\n",
        "        beginning=' '.join(NOVEL_TXT[:100].split())\n",
        "        printm(f'* Loaded book with **{len(NOVEL_TXT.strip().split())}** words')\n",
        "        printm(f'''* Book begins: {beginning}''')\n",
        "    return NOVEL_TXT\n",
        "\n",
        "NOVEL_TXT=get_novel_txt()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "### Alternatively to a URL, you can upload a file (txt, epub, pdf, docx, ...)",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0abe26c102604efd9f94fc678a383cab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Button(description='Upload text', style=ButtonStyle())"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Currently using uploaded file: uploaded_text.epub",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa84fd50f9724bd7bcb0cfb9b46994e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Button(description='Delete file', style=ButtonStyle())"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "### Checking input",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "* Using title: **Overstory**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "* Using filename: **Overstory**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "* Loading text from uploaded file: /content/tmp/uploaded_text.epub",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "* Loaded book with **56043** words",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "* Book begins: THE OVERSTORY A NOVEL RICHARD POWERS ![img](images/logo.jpg) W. W. NORTON & COMPANY _Independe",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "5bkgSHUa6JAi",
        "outputId": "4b2f7d6f-b5db-41e5-f39f-bbb4bad9d999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "#@title 📂 Choose where to store data\n",
        "#@markdown ##### Save text data to Google drive?\n",
        "#@markdown <small>This will save all generated data to your Google Drive, making downloading/uploading annotations and other data unnecessary. If yes, specify a directory path relative to your root Drive folder.</small>\n",
        "save = \"Yes, save in Google Drive\" #@param [\"Yes, save in Google Drive\", \"No, keep on temporary storage\"]\n",
        "path = \"DigHum/CharacterNetworks\" #@param {type:\"string\"}\n",
        "\n",
        "if 'Yes' in save:\n",
        "    # mount\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "    else:\n",
        "        printm('* Google Drive mounted at: /content/drive   ')\n",
        "    # create basedir\n",
        "    PATH_ROOT_DRIVE=os.path.join('/content/drive','My Drive',path)\n",
        "    if not os.path.exists(PATH_ROOT_DRIVE): os.makedirs(PATH_ROOT_DRIVE)\n",
        "    PATH_NOVELS_DRIVE=os.path.join(PATH_ROOT_DRIVE,'texts')\n",
        "    if not os.path.exists(PATH_NOVELS):\n",
        "        #@todo what if user changes mind about gdrive?\n",
        "        os.symlink(PATH_NOVELS_DRIVE, PATH_NOVELS)\n",
        "        printm(f'* Linking: {PATH_NOVELS} --> **{PATH_NOVELS_DRIVE}**')\n",
        "    else:\n",
        "        printm(f'* Linked: {PATH_NOVELS} --> **{PATH_NOVELS_DRIVE}**')\n",
        "\n",
        "\n",
        "URL_CORENLP='http://nlp.stanford.edu/software/stanford-corenlp-4.1.0.zip'\n",
        "MODEL_FN='stanford-corenlp-4.1.0-models.jar'\n",
        "PATH_TO_BOOKNLP_BINARY=os.path.abspath(os.path.join(PATH_TO_BOOKNLP,'runjava'))\n",
        "PATH_NOVEL=os.path.join(PATH_NOVELS,NOVEL_TITLE)\n",
        "ofn_novel=os.path.join(PATH_NOVEL,f'{NOVEL_TITLE}.txt')\n",
        "ofn=os.path.join(PATH_NOVEL,f'data.parses.{NOVEL_TITLE}.jsonl')\n",
        "ofn_meta=os.path.join(PATH_NOVEL,f'data.charmeta.{NOVEL_TITLE}.csv')\n",
        "ofn_meta_anno=os.path.join(PATH_NOVEL,f'data.charmeta.{NOVEL_TITLE}.anno.csv')\n",
        "ofn_booknlp_out=os.path.splitext(ofn_novel)[0]+'.booknlp'\n",
        "ofn_booknlp_toks=os.path.join(ofn_booknlp_out,'tokens.txt')\n",
        "ofn_fig_dir=os.path.join(PATH_NOVEL,'imgs')\n",
        "ofn_gif=os.path.join(PATH_NOVEL,'anim.gif')\n",
        "ofn_mp4=os.path.join(PATH_NOVEL,'anim.mp4')\n",
        "printm(f'* Path to novel data set to: **{PATH_NOVEL}**')\n",
        "if not os.path.exists(PATH_NOVEL): os.makedirs(PATH_NOVEL)\n",
        "if not os.path.exists(PATH_TOOLS): os.makedirs(PATH_TOOLS)\n",
        "if not NOVEL_TXT:\n",
        "    raise InvalidInput\n",
        "else:\n",
        "    with open(ofn_novel,'w') as of:\n",
        "        of.write(NOVEL_TXT)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "* Google Drive mounted at: /content/drive   ",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "* Linked: /content/texts --> **/content/drive/My Drive/DigHum/CharacterNetworks/texts**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "* Path to novel data set to: **/content/texts/Overstory**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "2cGcIoAzPP8B"
      },
      "source": [
        "#@title Once you are done, click on menu item **Runtime > Run all**\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Gweu3r7TUY"
      },
      "source": [
        "## 🔩 Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "NsTueiv-vRSa",
        "outputId": "538d56d5-3a0d-4631-f816-8f3963c42c5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Install dependencies\n",
        "!pip install dynetx fa2 pandas psutil humanize colour dimcli numpy moviepy ffmpeg pyvis networkx gender-guesser imageio-ffmpeg imageio -q\n",
        "\n",
        "\n",
        "#@title Import modules\n",
        "# imports\n",
        "import os,sys\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dynetx as dn\n",
        "from collections import Counter\n",
        "from shutil import which\n",
        "from colour import Color\n",
        "import numpy as np\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, widgets\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import math,os\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import plotly.express as px\n",
        "pd.options.display.max_rows=25\n",
        "import psutil\n",
        "import stat\n",
        "from pathlib import Path\n",
        "import time\n",
        "import humanize\n",
        "import datetime as dt\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 307kB 16.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 389kB 29.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 26.9MB 41.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25h  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "iWFNAPDd-1T_",
        "outputId": "559920cd-8846-4275-ff99-8a2e4de59a9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Install Booknlp\n",
        "os.chdir(PATH_TOOLS)\n",
        "if not os.path.exists(PATH_TO_BOOKNLP):\n",
        "    !git clone https://github.com/dbamman/book-nlp\n",
        "PATH_BOOKNLP_MODELS=os.path.join(PATH_TO_BOOKNLP,'lib',MODEL_FN)\n",
        "PATH_BOOKNLP_EXEC=os.path.join(PATH_TO_BOOKNLP,'runjava2')\n",
        "if not os.path.exists(PATH_BOOKNLP_MODELS):\n",
        "    !wget $URL_CORENLP\n",
        "    corenlp_fn=URL_CORENLP.split('/')[-1]\n",
        "    corenlp_dir=f'{corenlp_fn.split(\".zip\")[0]}'\n",
        "    !unzip -q \"$corenlp_fn\"\n",
        "    ifnfn=f'{corenlp_fn.split(\".zip\")[0]}/{MODEL_FN}'\n",
        "    !mv \"$ifnfn\" \"$PATH_BOOKNLP_MODELS\"\n",
        "    !rm \"$corenlp_fn\"\n",
        "    !rm -rf \"$corenlp_dir\"\n",
        "os.chdir(PATH_ROOT)\n",
        "\n",
        "def java_size(bytes, units=['b','k','m','g']):\n",
        "    \"\"\" Returns a human readable string representation of bytes \"\"\"\n",
        "    return str(bytes) + units[0] if bytes < 1024 else java_size(bytes>>10, units[1:])\n",
        "\n",
        "memstr=java_size(int(float(psutil.virtual_memory().available)*0.75))\n",
        "\n",
        "runjava_cmd=f\"\"\"\n",
        "#!/bin/sh\n",
        "\n",
        "# add all the jars anywhere in the lib/ directory to our classpath\n",
        "here=$(dirname $0)\n",
        "CLASSES=$here/bin\n",
        "CLASSES=$CLASSES:$(echo $here/lib/*.jar | tr ' ' :)\n",
        "CLASSES=$CLASSES:$here/book-nlp.jar\n",
        "\n",
        "java -XX:ParallelGCThreads=2 -Xmx{memstr} -ea -classpath $CLASSES $*\n",
        "\"\"\"\n",
        "with open(PATH_BOOKNLP_EXEC,'w') as of: of.write(runjava_cmd)\n",
        "!chmod +x \"$PATH_BOOKNLP_EXEC\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'book-nlp'...\n",
            "remote: Enumerating objects: 27, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 313 (delta 7), reused 20 (delta 2), pack-reused 286\u001b[K\n",
            "Receiving objects: 100% (313/313), 75.23 MiB | 21.57 MiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n",
            "--2020-11-02 20:06:24--  http://nlp.stanford.edu/software/stanford-corenlp-4.1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/software/stanford-corenlp-4.1.0.zip [following]\n",
            "--2020-11-02 20:06:24--  https://nlp.stanford.edu/software/stanford-corenlp-4.1.0.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 504773765 (481M) [application/zip]\n",
            "Saving to: ‘stanford-corenlp-4.1.0.zip’\n",
            "\n",
            "ford-corenlp-4.1.0.  54%[=========>          ] 260.51M   675KB/s    eta 4m 59s "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX3W6A726Puv"
      },
      "source": [
        "## 🔨 Parse\n",
        "\n",
        "This will take ~15 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "IQ82a6Dn6Puy"
      },
      "source": [
        "#@title Parse text using BookNLP\n",
        "def parse_text(path_txt):\n",
        "    import time\n",
        "    now=time.time()\n",
        "    if not path_txt: return    \n",
        "    path_out=ofn_booknlp_out\n",
        "    path_toks=ofn_booknlp_toks\n",
        "    cmd=f'cd \"{PATH_TO_BOOKNLP}\" && ./{os.path.basename(PATH_BOOKNLP_EXEC)} novels/BookNLP -doc {path_txt} -printHTML -p {path_out} -tok {path_toks} -f'\n",
        "    # print('>>',cmd)\n",
        "    !{cmd} #os.system(cmd)\n",
        "    os.rename(os.path.join(path_out,'book.id.html'), os.path.join(path_out,'parsed.html'))\n",
        "    os.rename(os.path.join(path_out,'book.id.book'), os.path.join(path_out,'parsed.json'))\n",
        "    nownow=time.time()\n",
        "    with open(path_txt) as tf: numwords=len(tf.read().strip().split())\n",
        "    speed=numwords/(nownow-now)\n",
        "    print(f'\\n >> Finished parsing in {humanize.naturaldelta(dt.timedelta(seconds=nownow-now))} ({speed} words/sec)')\n",
        "#@title\n",
        "# Parse! This will take 10-15 minutes for most novels... time to make coffee?\n",
        "if not os.path.exists(ofn_booknlp_toks): parse_text(ofn_novel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "Zrb5Am8n6PvQ"
      },
      "source": [
        "#@title Load generated character data\n",
        "def read_parsed_json(path_parsed_json):\n",
        "    import json,os\n",
        "    from collections import defaultdict,Counter\n",
        "    #json.loads(path_parsed_json)\n",
        "    dat=json.load(open(path_parsed_json))\n",
        "    keys=[]\n",
        "    nullchar=defaultdict(Counter)\n",
        "    text_id=path_parsed_json.split('/')[-3]\n",
        "    for char in dat['characters']:\n",
        "        if not char['names']: continue\n",
        "        names=[x['n'] for x in char['names']]\n",
        "        \n",
        "        chardx={'name':names[0], 'id':char['id'], 'names':', '.join(names), 'text_id':text_id}\n",
        "        num=0\n",
        "        for key in ['agent','patient','poss','mod','speaking']:\n",
        "            chardx['num_'+key]=len(char[key])\n",
        "            num+=chardx['num_'+key]\n",
        "            # chardx['words_'+key]=words=[]\n",
        "            # for event in char[key]:\n",
        "            #     if 'w' in event:\n",
        "            #         wtxt=event['w']\n",
        "            #         wlist=word_tokenize(wtxt) if ' ' in wtxt else [wtxt]\n",
        "            #         wlist=[w.lower() for w in wlist if w and w[0].isalpha()]\n",
        "            #         words+=wlist\n",
        "        num+=1\n",
        "        chardx['num']=num\n",
        "        yield chardx\n",
        "\n",
        "# Load jsons into character metadata\n",
        "char_jsons=list(read_parsed_json(os.path.join(ofn_booknlp_out,'parsed.json')))\n",
        "char_df=pd.DataFrame(char_jsons)\n",
        "id2name=dict(zip(char_df.id,char_df.name))\n",
        "printm(f'Found **{len(char_jsons)}** characters, for a total of **{sum(char_df.num)}** mentions.')\n",
        "topn=10\n",
        "printm(f'#### Top {topn} characters')\n",
        "display(char_df.sort_values('num',ascending=False)[['name','num','names']].head(topn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "2gnL7vC-0qYo"
      },
      "source": [
        "#@title Load word-by-word parse data\n",
        "# load and gen\n",
        "def load_tokdf(ofn_booknlp_toks=ofn_booknlp_toks):\n",
        "    tok_df=pd.read_csv(ofn_booknlp_toks,sep='\\t',error_bad_lines=False,engine='python',warn_bad_lines=False)\n",
        "    tok_df['isChar']=tok_df['characterId'].apply(lambda x: int(x!=-1))\n",
        "    tok_df['isWord']=1\n",
        "    return tok_df\n",
        "tok_df=load_tokdf(ofn_booknlp_toks=ofn_booknlp_toks)\n",
        "# show\n",
        "from IPython.display import Markdown, display, Javascript\n",
        "# nicer print func\n",
        "def printm(x): display(Markdown(x))\n",
        "printm('#### Word-level data')\n",
        "printm(f'* Number of words: {len(tok_df)}')\n",
        "printm(f'* Number of sentences: {len(set(tok_df.sentenceID))}')\n",
        "printm(f'* Number of paragraphs: {len(set(tok_df.paragraphId))}')\n",
        "printm(f'* Number of character mentions: {sum(tok_df.isChar)}')\n",
        "display(tok_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWA-to8x2rhL"
      },
      "source": [
        "'``' in set(tok_df.originalWord)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQR_q3tZvRSz"
      },
      "source": [
        "## 🤔 Examine character data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "PfZAMbM56PvX"
      },
      "source": [
        "#@title Prepare metadata for manual annotation\n",
        "if 1:# not os.path.exists(ofn_meta):\n",
        "    # Guess gender of characters?\n",
        "    import gender_guesser.detector as gender\n",
        "    gd = gender.Detector()\n",
        "\n",
        "    prefix_clues={\n",
        "        'female':{'Ms.', 'Ms ','Mrs.','Mrs ','Miss ','Madame','Mme.',\n",
        "                  'Mme ','Signorina','Maestra ',\n",
        "                  'Lady '},\n",
        "        'male':{'Don ','Signor ','Mr.','Mr ','Maestro ','Lord ','Sir '}\n",
        "    }\n",
        "\n",
        "    def guess_gender(name,gd=gd):\n",
        "        if not name: return None\n",
        "\n",
        "        for gndr,prfxs in prefix_clues.items():\n",
        "            for p in prfxs:\n",
        "                if name.startswith(p):\n",
        "                    return gndr\n",
        "        \n",
        "        gend=gd.get_gender(name).replace('mostly_','')\n",
        "        return gend\n",
        "    char_df['gender']=char_df.name.apply(guess_gender)\n",
        "    dfm=char_df#.groupby(['name','gender','id']).sum().reset_index()\n",
        "\n",
        "    # create other fields\n",
        "    dfm['name_real']=dfm['name']\n",
        "    dfm['other']=''\n",
        "    dfm['notes']=''\n",
        "    dfm['race']=''\n",
        "    dfm['class']=''\n",
        "    dfm_save=dfm[['id','name','name_real','num','gender','race','class','other','notes']].sort_values('num',ascending=False)\n",
        "    dfm_save.to_csv(ofn_meta,index=False)\n",
        "    # if not os.path.exists(ofn_meta_anno):\n",
        "        # dfm_save.to_csv(ofn_meta_anno,index=False)\n",
        "    printm('#### Metadata generated automatically')\n",
        "    display(dfm_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mDekpVyGCokK"
      },
      "source": [
        "#@title Download/upload metadata for manual annotation\n",
        "from google.colab import files\n",
        "def download_anno(x):\n",
        "    files.download(ofn_meta)\n",
        "dbutton = widgets.Button(description=\"Download as CSV\")\n",
        "dbutton.on_click(download_anno)\n",
        "printm('''### Download automatically generated character metadata''')\n",
        "printm('''Open in a spreadsheet editor (e.g. excel) and change the names\n",
        "in the column 'name_real' to rename the character.\n",
        "Delete the name there to declare that character name invalid.\n",
        "The other columns allow you to set variables to color or size the networks by.\n",
        "''')\n",
        "display(dbutton)\n",
        "\n",
        "printm('### Upload manually refined character metadata')\n",
        "printm('''When you're done, click \"Upload\" and upload the new CSV below.\n",
        "If you saved your sheet as an excel file, export it as CSV before uploading.\n",
        "''')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def upload_anno(x):\n",
        "    from google.colab import files\n",
        "    FILES = files.upload()\n",
        "    if not FILES: return\n",
        "    fn=list(FILES.keys())[0]\n",
        "    fnpre,ext=os.path.splitext(fn)\n",
        "    if ext not in {'.csv'}:\n",
        "        print('File must be a CSV file. (e.g. In excel, export as CSV.)')\n",
        "        raise InvalidInput\n",
        "    !mv \"$fn\" \"$ofn_meta_anno\"\n",
        "\n",
        "\n",
        "button = widgets.Button(description=\"Upload annotations\")\n",
        "button.on_click(upload_anno)\n",
        "display(button)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "QedvKrFk6Pvv"
      },
      "source": [
        "#@title Reload and filter metadata\n",
        "# load csv\n",
        "\n",
        "min_num_mentions=widgets.IntSlider(min=1,max=50,value=5)\n",
        "printm('### Filter by the minimum number of mentions')\n",
        "\n",
        "def load_dfm():\n",
        "    ifn=ofn_meta_anno if os.path.exists(ofn_meta_anno) else ofn_meta\n",
        "    dfm=pd.read_csv(ifn).fillna('').rename(columns={'num':'num_total', 'count':'num_total', 'name_standardized':'name_real','id':'characterId'})\n",
        "    dfm=dfm[(dfm.name_real.apply(lambda x: x[0].isalpha()))] \n",
        "    return dfm\n",
        "\n",
        "\n",
        "def filter_metadata(min_num_mentions=min_num_mentions):\n",
        "    dfm=load_dfm()\n",
        "    # show changes\n",
        "    name2real=dict(zip(dfm.name,dfm.name_real))\n",
        "    for _name,_name_real in sorted(name2real.items()):\n",
        "        if _name!=_name_real:\n",
        "            printm(f'* Changed: {_name} --> {_name_real}')\n",
        "\n",
        "    len1=len(dfm)    \n",
        "    dfmr=dfm#.rename()\n",
        "    strcols=set(dfmr.columns) - {'num_total','name'}\n",
        "    \n",
        "    newld=[]\n",
        "    for name,namedf in dfmr.groupby('name_real'):\n",
        "        num_total=namedf.num_total.sum()\n",
        "        if num_total<min_num_mentions: continue\n",
        "        ncdf=namedf.mode()\n",
        "        common_d=dict(ncdf.iloc[0])\n",
        "        namedx={**common_d, **{'num_total':num_total,}}\n",
        "        newld.append(namedx)\n",
        "\n",
        "    dfmr=pd.DataFrame(newld)#dfmr[dfmr.num_total>=min_num_mentions].groupby(list(strcols)).sum().reset_index()\n",
        "    len2=len(dfmr)\n",
        "    printm(f'* Filtered: {len2} of {len1} characters remaining because mentioned at least {min_num_mentions} times')\n",
        "    # sum by new names\n",
        "    dfmr=dfmr.sort_values('num_total') #[dfmr.name.str.startswith('Mrs. D')] #.tail(10)\n",
        "    # print(res)\n",
        "    return dfmr\n",
        "\n",
        "live_dfm=interact(filter_metadata,min_num_mentions=min_num_mentions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVMhWhGz6Pvy"
      },
      "source": [
        "## 🕸 Generate social network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wik1oa-E-6sO"
      },
      "source": [
        "dfm = load_dfm()\n",
        "dfm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y4TNySN-IrP"
      },
      "source": [
        "dfmr = filter_metadata(**live_dfm.widget.kwargs)\n",
        "dfmr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANrH1zUd8zNp"
      },
      "source": [
        "def load_alldf():\n",
        "    # dfm\n",
        "    dfm=load_dfm() \n",
        "    # filtered dfm\n",
        "    dfmr = filter_metadata(**live_dfm.widget.kwargs)\n",
        "    # tokens\n",
        "    tok_df=load_tokdf(ofn_booknlp_toks=ofn_booknlp_toks)\n",
        "    tok_cols = set(tok_df.columns) - set(dfm.columns)\n",
        "    all_df=tok_df[['characterId']+list(tok_cols)].merge(dfm,on='characterId',how='left').fillna('')\n",
        "    return all_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6sX1HtrMpLT"
      },
      "source": [
        "# adf=load_alldf()\n",
        "# adf[adf.characterId!=-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "od-kOfW0sucL"
      },
      "source": [
        "#@title Generate dynamic network from interactions\n",
        "NET_STATS=['degree','degree_centrality','betweenness_centrality','eigenvector_centrality','closeness_centrality']\n",
        "slice_length=widgets.Dropdown(options=[1,5,10,50,100,250,500,1000,2000,5000,10000,25000],value=500,description='Length')\n",
        "weight_slider=widgets.IntSlider(min=1, max=10, step=1, value=2)\n",
        "mindegree_slider=widgets.IntSlider(min=0, max=10, step=1, value=1)\n",
        "weight_factor=widgets.IntSlider(min=1, max=100, step=1, value=5)\n",
        "time_units=dict([('words','tokenId'), ('sentences','sentenceID'), ('paragraphs','paragraphId')])\n",
        "time_type=widgets.Dropdown(options=list(time_units.keys()),description='Unit of time',value='words')\n",
        "\n",
        "def make_dyn_charnet(name_key=fixed('name_real'),t_unit='words',slice_length=1000):\n",
        "    roundby=slice_length\n",
        "    t_key=time_units.get(t_unit,'tokenId')\n",
        "    printm(f'* Divide text every {roundby} {t_unit}')\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    # init\n",
        "    dg = dn.DynGraph(edge_removal=False)\n",
        "    all_df=load_alldf()\n",
        "    all_df['slice']=all_df[t_key].apply(lambda x: x//roundby)\n",
        "    \n",
        "    # t=paragraph\n",
        "    last_char=None\n",
        "    ts=set()\n",
        "    t=0\n",
        "    edges=set()\n",
        "    name2real=dict(zip(all_df.name, all_df.name_real))\n",
        "\n",
        "    grps=sorted(list(all_df.groupby('slice')))\n",
        "    grp_ld=[]\n",
        "    edge_list=[]\n",
        "    for sl,sldf in grps:\n",
        "        t=sl\n",
        "        chars_in_slice=[x for x in sorted(list(set(sldf[name_key]))) if x]\n",
        "        #printm(f' * At t={t}, found {len(chars_in_slice)} unique characters: {\", \".join(chars_in_slice)}')\n",
        "        for a in chars_in_slice:\n",
        "            for b in chars_in_slice:\n",
        "                if b<=a: continue\n",
        "                dg.add_interaction(u=a,v=b,t=t)\n",
        "                edge_list.append((t,a,b))\n",
        "        grp_dx={\n",
        "            't':t,\n",
        "            'chars':chars_in_slice,\n",
        "            'num_chars':len(chars_in_slice),\n",
        "        }\n",
        "        grp_ld.append(grp_dx)\n",
        "    grp_df=pd.DataFrame(grp_ld)\n",
        "\n",
        "    # show stats\n",
        "    ts=dg.temporal_snapshots_ids()\n",
        "    chartups_dyn={tuple(sorted([u,v])+[t]) for (u, v, op, t) in dg.stream_interactions()}\n",
        "    chartups_stat={tuple(sorted([u,v])) for (u, v, op, t) in dg.stream_interactions()}\n",
        "    printm(f'* {len(ts)} time slices')\n",
        "    printm(f'* {len(chartups_stat)} unique character-to-character edges')\n",
        "    printm(f'* {len(edge_list)} total interactions')\n",
        "    display(grp_df)\n",
        "    # display(edge_list[:10])\n",
        "    return dg,grp_df,edge_list\n",
        "\n",
        "# show opts\n",
        "charnet_dynamic_i=interactive(\n",
        "    make_dyn_charnet,\n",
        "    all_df=fixed(all_df),\n",
        "    t_unit=time_type,\n",
        "    slice_length=slice_length\n",
        ")\n",
        "charnet_dynamic_i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "DnrvgwoL3ICh"
      },
      "source": [
        "#@title Display and fine-tune network\n",
        "# Convert to static\n",
        "\n",
        "\n",
        "def to_static(edge_list,t_start=None,t_end=None,min_weight=2,name_key='name_real',stats=NET_STATS,min_degree=1):\n",
        "    # printm(f'#### Generating static network with minimum weight set to {min_weight}')\n",
        "    import networkx as nx\n",
        "    g=nx.Graph()\n",
        "\n",
        "    num_interactions_d=Counter()\n",
        "    for t,u,v in sorted(edge_list):\n",
        "        if t_start and t<t_start: continue\n",
        "        if t_end and t>t_end: continue\n",
        "        num_interactions_d[u]+=1\n",
        "        num_interactions_d[v]+=1\n",
        "        if not g.has_edge(u,v):\n",
        "            g.add_edge(u,v,t=[t],weight=1)\n",
        "        else:\n",
        "            g[u][v]['weight']+=1\n",
        "            g[u][v]['t']+=[t]\n",
        "\n",
        "    if min_weight:\n",
        "        for a,b,d in list(g.edges(data=True)):\n",
        "            if d['weight']<min_weight:\n",
        "                g.remove_edge(a,b)\n",
        "\n",
        "    # add metadata\n",
        "    for n in g.nodes():\n",
        "        # print(n,'??')\n",
        "        ndf=dfm[dfm[name_key]==n]\n",
        "        ncdf=ndf.mode()\n",
        "        try:\n",
        "            common_d=dict(ncdf.iloc[0])\n",
        "        except IndexError:\n",
        "            continue\n",
        "        for k,v in common_d.items(): g.nodes[n][k]=v\n",
        "        g.nodes[n]['num_interactions']=num_interactions_d[n]\n",
        "        g.nodes[n]['num_mentions']=ndf['num_total'].sum() #.iloc[0]['num_total']\n",
        "\n",
        "    # include node stats\n",
        "    for stat in stats:\n",
        "        try:\n",
        "            func=getattr(nx,stat)\n",
        "            for n,v in dict(func(g)).items():\n",
        "                g.nodes[n][stat]=v\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # return graph\n",
        "    if min_degree:\n",
        "        for n in list(g.nodes()):\n",
        "            if g.nodes[n]['degree']<min_degree:\n",
        "                g.remove_node(n)\n",
        "\n",
        "    return g\n",
        "\n",
        "\n",
        "#@title\n",
        "def layout(g):\n",
        "    from fa2 import ForceAtlas2\n",
        "    forceatlas2 = ForceAtlas2(\n",
        "        # Behavior alternatives\n",
        "        outboundAttractionDistribution=True,  # Dissuade hubs\n",
        "        linLogMode=False,  # NOT IMPLEMENTED\n",
        "        adjustSizes=False,  # Prevent overlap (NOT IMPLEMENTED)\n",
        "        edgeWeightInfluence=1.0,\n",
        "\n",
        "        # Performance\n",
        "        jitterTolerance=1.0,  # Tolerance\n",
        "        barnesHutOptimize=True,\n",
        "        barnesHutTheta=1.2,\n",
        "        multiThreaded=False,  # NOT IMPLEMENTED\n",
        "\n",
        "        # Tuning\n",
        "        scalingRatio=2.0,\n",
        "        strongGravityMode=False,\n",
        "        gravity=1.0,\n",
        "\n",
        "        # Log\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    pos = forceatlas2.forceatlas2_networkx_layout(g, pos=None, iterations=2000)\n",
        "    return pos\n",
        "\n",
        "\n",
        "#@title Drawing static networks\n",
        "def drawnet_nx(g,ofn='net.png',pos=None,weight_factor=1,size_by='degree',size_factor=1000,save=True,title=None,color_by=None,default_color='gray',color_start='red',color_end='blue',default_size=300):\n",
        "    from matplotlib import pyplot as plt\n",
        "    fig = plt.figure(figsize=(10,10))#,facecolor=(0, 0, 0))\n",
        "    if title: fig.suptitle(title, fontsize=16)\n",
        "    nodelist=g.nodes()\n",
        "    labels=dict((n,n) for n in nodelist)\n",
        "    try:\n",
        "        size_vals=x=np.array([g.nodes[n].get(size_by,np.nan) for n in nodelist])\n",
        "        normalized = (x-min(x))/(max(x)-min(x))\n",
        "        node_size=[x*size_factor if x is not np.nan else default_size for x in normalized]\n",
        "    except:\n",
        "        node_size=default_size\n",
        "    node_color=[]\n",
        "\n",
        "    edgelist=list(g.edges())\n",
        "    edge_size=[g[a][b]['weight']*weight_factor for a,b in edgelist]\n",
        "    try:\n",
        "        edge_size_vals=x=np.array([g[a][b]['weight'] for a,b in edgelist])\n",
        "        edge_normalized = (x-min(x))/(max(x)-min(x))\n",
        "        edge_size=[x*weight_factor if x is not np.nan else 1 for x in edge_normalized]\n",
        "    except:\n",
        "        edge_size=1\n",
        "\n",
        "\n",
        "    if color_by:\n",
        "        color_types=sorted(list(set(g.nodes[n][color_by] for n in g.nodes())))\n",
        "        num_colors=len(color_types)\n",
        "        spectrum=list(Color(color_start).range_to(Color(color_end),num_colors))\n",
        "        colormap=dict(zip(color_types, spectrum))\n",
        "        node_color=[colormap[g.nodes[n][color_by]].hex for n in g.nodes()]\n",
        "    else:\n",
        "        node_color=default_color\n",
        "\n",
        "    nx.draw_networkx(\n",
        "        g,\n",
        "        pos=pos,\n",
        "        labels=labels,\n",
        "        nodelist=nodelist,\n",
        "        node_size=node_size,\n",
        "        edgelist=edgelist,\n",
        "        width=edge_size,\n",
        "        font_color='black',\n",
        "        font_weight='bold',\n",
        "        font_size=12,\n",
        "        node_color=node_color,\n",
        "        edge_color='teal'\n",
        "    )\n",
        "    if save:\n",
        "        plt.savefig(ofn)\n",
        "        plt.close()\n",
        "    else:\n",
        "        return plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate\n",
        "# printm('### Set minimum weight')\n",
        "# display(weight_slider)\n",
        "min_degree_slider = widgets.IntSlider(min=1,max=10,step=1,value=2,desc='Minimum degree')\n",
        "\n",
        "# @interact\n",
        "def make_static(min_weight=weight_slider,min_degree=min_degree_slider):\n",
        "    # get current data \n",
        "    charnet_dynamic,charnet_dynamic_df,charnet_dynamic_edgelist=charnet_dynamic_i.result\n",
        "    dg=charnet_dynamic\n",
        "\n",
        "    charnet_static=g=to_static(charnet_dynamic_edgelist,min_weight=min_weight,min_degree=min_degree)\n",
        "    printm(f'Graph generated with {g.order()} nodes and {g.size()} edges')\n",
        "    charnet_static_df=pd.DataFrame(dict(charnet_static.nodes[n]) for n in charnet_static.nodes())\n",
        "    charnet_static_df_edges=pd.DataFrame({'source':a, 'target':b, **d} for a,b,d in charnet_static.edges(data=True))    \n",
        "    \n",
        "    # printm('### Edge data')\n",
        "    # display(charnet_static_df_edges.sort_values('weight',ascending=False))\n",
        "\n",
        "    # printm('### Node data')\n",
        "    # display(charnet_static_df.sort_values('num_total',ascending=False))\n",
        "    # printm('### Graph preview')\n",
        "    pos=layout(g)\n",
        "    title=f'{NOVEL_TITLE} (w>={min_weight})'\n",
        "    try:\n",
        "        drawnet_nx(\n",
        "            g,\n",
        "            save=False,\n",
        "            pos=pos,\n",
        "            title=title,\n",
        "            weight_factor=10\n",
        "        )\n",
        "    except ValueError:\n",
        "        pass\n",
        "    return charnet_static, charnet_static_df, charnet_static_df_edges\n",
        "\n",
        "# charnet_static_i=interactive(make_static,min_weight=weight_slider)\n",
        "# charnet_static_i\n",
        "\n",
        "\n",
        "#@title Fiddle with settings\n",
        "widg_sizeby=widgets.Dropdown(options=['num_total']+sorted(list(NET_STATS)))\n",
        "# charnet_static,charnet_static_df=charnet_static_i.result\n",
        "# node_features=set(charnet_static_df.select_dtypes('number').columns) - {'id'}\n",
        "widg_pos_method = widgets.Dropdown(options=[('Layout from final state','final'), ('Layout evolves','evolve')],desc='Layout method')\n",
        "\n",
        "def show_graph(t_start=time_slider1,\n",
        "               t_end=time_slider2,\n",
        "               min_weight=weight_slider,\n",
        "               color_by=widg_colorby,\n",
        "               size_by=widg_sizeby,\n",
        "               weight_factor=weight_factor,\n",
        "               min_degree=min_degree_slider,\n",
        "               save=fixed(False),\n",
        "               ofn=fixed(None),\n",
        "               pos=fixed(None),\n",
        "               title=fixed(None),\n",
        "               pos_method=widg_pos_method):\n",
        "    if not title: title=f'Character network for {NOVEL_TITLE} (t={t_start}-{t_end}) (w>={min_weight})'\n",
        "    try:\n",
        "        # load dynamic network\n",
        "        charnet_dynamic,charnet_dynamic_df,charnet_dynamic_edgelist=charnet_dynamic_i.result\n",
        "    \n",
        "        # get network up to this point\n",
        "        g_sofar=to_static(\n",
        "            charnet_dynamic_edgelist,\n",
        "            min_weight=min_weight,\n",
        "            min_degree=min_degree,\n",
        "            t_start=t_start,\n",
        "            t_end=t_end\n",
        "        )\n",
        "\n",
        "        # positions set?\n",
        "        if pos is None:\n",
        "            # set by end stage?\n",
        "            if pos_method=='final':\n",
        "                # get total static\n",
        "                g=to_static(\n",
        "                    charnet_dynamic_edgelist,\n",
        "                    min_weight=min_weight,\n",
        "                    min_degree=min_degree,\n",
        "                )\n",
        "                # set positions from total static\n",
        "                pos=layout(g)\n",
        "            else:\n",
        "                pos=layout(g_sofar)\n",
        "        \n",
        "        # draw figure\n",
        "        drawnet_nx(\n",
        "            g_sofar,\n",
        "            save=save,\n",
        "            ofn=ofn,\n",
        "            pos=pos,\n",
        "            size_by=widg_sizeby.value,\n",
        "            color_by=widg_colorby.value,\n",
        "            weight_factor=weight_factor,\n",
        "            title=title\n",
        "        )\n",
        "    except Exception as e:\n",
        "        #printm(f'**!! Error: {e}**')\n",
        "        pass\n",
        "\n",
        "\n",
        "graph_configurator = interactive(show_graph)\n",
        "graph_configurator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErumNfe105wv"
      },
      "source": [
        "## 🎥 Generating dynamic network visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "AP79AxUY6Pv-"
      },
      "source": [
        "#@title Generate underlying images\n",
        "def drawnets(odir=ofn_fig_dir,pos=None):\n",
        "    charnet_dynamic,charnet_dynamic_df,charnet_dynamic_edgelist=charnet_dynamic_i.result\n",
        "    ts=charnet_dynamic.temporal_snapshots_ids()\n",
        "    if not os.path.exists(odir): os.makedirs(odir)\n",
        "    \n",
        "    # get pos\n",
        "    if pos is None:\n",
        "        g=to_static(\n",
        "            charnet_dynamic_edgelist,\n",
        "            min_weight=weight_slider.value,\n",
        "            min_degree=min_degree_slider.value,\n",
        "        )\n",
        "        pos=layout(g)\n",
        "    \n",
        "    for t in tqdm(ts):\n",
        "        ofn_img=os.path.join(odir,f'net-{str(t).zfill(4)}.png')\n",
        "        title=f'{NOVEL_TITLE_NICE} (t={str(t).zfill(4)})'\n",
        "        try:\n",
        "            show_graph(\n",
        "                t_start=0,\n",
        "                t_end=t,\n",
        "                save=True,\n",
        "                ofn=ofn_img,\n",
        "                title=title,\n",
        "                min_weight=weight_slider.value,\n",
        "                color_by=widg_colorby.value,\n",
        "                size_by=widg_sizeby.value,\n",
        "                weight_factor=weight_factor.value,\n",
        "                min_degree=min_degree_slider.value,\n",
        "                pos=pos\n",
        "            )\n",
        "        except IndexError:\n",
        "            pass\n",
        "\n",
        "def do_drawnets(*x,**y):\n",
        "    drawnets()\n",
        "\n",
        "if not os.path.exists(ofn_fig_dir) or not os.listdir(ofn_fig_dir):\n",
        "    res=do_drawnets()\n",
        "\n",
        "button2=widgets.Button(description='Regenerate images')\n",
        "button2.on_click(do_drawnets)\n",
        "button2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ajNd0k7PM13Y"
      },
      "source": [
        "#@title Generate mp4 video from images\n",
        "def make_vid_from_folder(*x,image_folder=ofn_fig_dir,ofn=ofn_mp4,fps=15):\n",
        "    import moviepy.video.io.ImageSequenceClip\n",
        "\n",
        "    image_files = [os.path.join(image_folder,img) for img in sorted(os.listdir(image_folder)) if img.endswith(\".png\")]\n",
        "    clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
        "    clip.write_videofile(ofn)\n",
        "\n",
        "if not os.path.exists(ofn_mp4): make_vid_from_folder()\n",
        "button3=widgets.Button(description='Regenerate Video')\n",
        "button3.on_click(make_vid_from_folder)\n",
        "# display(button3)\n",
        "\n",
        "# show video\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "from base64 import b64encode\n",
        "mp4 = open(ofn_mp4,'rb').read()\n",
        "display(button3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FAzKh8aj0n_O"
      },
      "source": [
        "#@title Show video\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "display(HTML(\"\"\"\n",
        "<video width=666 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-sAcA9YO6PwF"
      },
      "source": [
        "#@title Generate gif from images\n",
        "def make_gif_from_folder(x,folder=ofn_fig_dir,ofn=ofn_gif):\n",
        "    import imageio\n",
        "    images = []\n",
        "    for fn in sorted(os.listdir(folder)):\n",
        "        if fn.endswith('.png'):\n",
        "            with open(os.path.join(folder,fn),'rb') as f:\n",
        "                images.append(imageio.imread(f))\n",
        "    imageio.mimsave(ofn, images)\n",
        "\n",
        "\n",
        "if not os.path.exists(ofn_gif): make_gif_from_folder(1)\n",
        "\n",
        "button2=widgets.Button(description='Regenerate GIF')\n",
        "button2.on_click(make_gif_from_folder)\n",
        "\n",
        "# show gif?\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "from pathlib import Path\n",
        "gifPath = Path(ofn_gif)\n",
        "if os.path.exists(gifPath):\n",
        "    # Display GIF in Jupyter, CoLab, IPython\n",
        "    with open(gifPath,'rb') as f:\n",
        "        display.Image(data=f.read(), format='png')\n",
        "\n",
        "button2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG-0CIs7Lv3c"
      },
      "source": [
        "## 📐 Analyze results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3mVzRxGOWP6o"
      },
      "source": [
        "#@title Distribution of character attention\n",
        "# create\n",
        "dfm=filter_metadata(min_num_mentions=min_num_mentions.value)\n",
        "\n",
        "all_df=dfm.merge(tok_df,on='characterId',how='right').fillna('')\n",
        "color_by=list(dfm.columns)[list(dfm.columns).index('gender'):]+['none']\n",
        "dfm['none']='none'\n",
        "# res=char_df.num.plot(kind='density',width=666)\n",
        "widg_colorby=widgets.Dropdown(options=color_by,description='Group by')\n",
        "num_top_chars=widgets.IntSlider(min=5,max=len(dfm)+5,step=5,value=25,description='# Top Chars')\n",
        "\n",
        "@interact\n",
        "def showtopn(num_top=num_top_chars):\n",
        "    n=num_top\n",
        "    printm(f'#### Median number of mentions per character (all): {int(dfm.num_total.median())}')\n",
        "    return px.bar(\n",
        "        dfm.sort_values('num_total',ascending=True).iloc[-n:],\n",
        "        y=\"name_real\",\n",
        "        x=\"num_total\",\n",
        "        hover_data=['name_real','num_total','gender'],\n",
        "        title=f'Distribution of mentions over top {n} characters',\n",
        "        text='num_total',\n",
        "        width=666,\n",
        "        height=666/25 * n,\n",
        "        orientation='h'\n",
        "    )    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FKGTMMtZDqm6"
      },
      "source": [
        "#@title Distribution of attention by group\n",
        "@interact\n",
        "def show_histogram(group_by=widg_colorby):\n",
        "    \n",
        "\n",
        "    printm(f'### Distribution by {group_by}')\n",
        "    #if group_by!='none':\n",
        "    xvals=[]\n",
        "    for cat,catdf in sorted(dfm.groupby(group_by),key=lambda x: -len(x[1])):\n",
        "        totalperc=round(sum(catdf.num_total)/sum(dfm.num_total)*100,1)\n",
        "        printm(f'#### {len(catdf)} {cat} characters make up {totalperc}% of all mentions')\n",
        "        # printm(f'* Median number of mentions per character ({cat}): {int(catdf.num_total.median())}')\n",
        "        stats=[f'{row.name_real} ({row.num_total})' for i,row in catdf.sort_values('num_total',ascending=False).iterrows()]\n",
        "        printm(f'''* {', '.join(stats)} [median={int(catdf.num_total.median())}]''')\n",
        "        xvals+=[cat]\n",
        "    \n",
        "    # display(px.histogram(dfm, x='num_total', color=group,marginal='rug')\n",
        "\n",
        "    fig=px.box(\n",
        "        dfm.sort_values(group_by),\n",
        "        y=\"num_total\",\n",
        "        range_y=(.9,max(dfm.num_total)+10),\n",
        "        log_y=True,\n",
        "        x=group_by,\n",
        "        width=666,\n",
        "        color=group_by,\n",
        "        points=\"all\",\n",
        "        hover_data=[x for x in ['name_real','num_total'] + color_by if x!='none'],\n",
        "        title=f'Number of mentions for characters by {group_by}'\n",
        "    )\n",
        "\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dI33o-pKFwHm"
      },
      "source": [
        "#@title Show character density across length of text\n",
        "# Other token stats\n",
        "yopts=widgets.Dropdown(options=[('# of mentions','num_mentions'),('# of unique','num_chars')], desription='Y value')\n",
        "charnet_dynamic,charnet_dynamic_df,charnet_dynamic_edgelist=charnet_dynamic_i.result\n",
        "ts=charnet_dynamic.temporal_snapshots_ids()\n",
        "time_slider1=widgets.IntSlider(min=ts[0], max=ts[-1], step=10, value=ts[0])\n",
        "time_slider2=widgets.IntSlider(min=ts[0], max=ts[-1], step=10, value=ts[-1])\n",
        "\n",
        "@interact\n",
        "def show_density(slice_length=slice_length,color_by=widg_colorby,y_value=yopts):\n",
        "    num_words_in_preview=30\n",
        "    slice2txt=defaultdict(list)\n",
        "    all_df['slice']=all_df.tokenId.apply(lambda x: x//slice_length*slice_length)\n",
        "    all_df['none']='none'\n",
        "    slice_ld=[]\n",
        "    for sl,sldf in all_df.groupby('slice'):\n",
        "        slice_dx={'slice':sl}\n",
        "        # get preview\n",
        "        slice_dx['preview']=[]\n",
        "        for i,row in sldf.iterrows():\n",
        "            if not str(row['originalWord']).strip(): continue\n",
        "            if len(slice_dx['preview'])>num_words_in_preview:break\n",
        "            slice_dx['preview']+=[str(row['originalWord']).strip()+str(' ' if row['whitespaceAfter']=='S' else '')]\n",
        "        slice_dx['preview']=''.join(slice_dx['preview'])+'...'\n",
        "        # count by category\n",
        "        num_words=len(sldf)\n",
        "        for cat,catdf in sldf.groupby(color_by):\n",
        "            num_mentions=sum(catdf['isChar'])\n",
        "            num_chars=len(set(catdf['characterId']))\n",
        "            slice_cat_dx=dict(**slice_dx, **{'color_by':cat, 'num_mentions':num_mentions, 'num_chars':num_chars, 'color_by':cat})\n",
        "            slice_ld.append(slice_cat_dx)\n",
        "\n",
        "    slicedf=pd.DataFrame(slice_ld)\n",
        "    printm(f'Median number of unique characters = **{slicedf.num_chars.median()}** names per {slice_length} words')\n",
        "    printm(f'Median number of character mentions = **{slicedf.num_mentions.median()}** names per {slice_length} words')\n",
        "\n",
        "\n",
        "    import plotly.express as px\n",
        "    return px.line(slicedf,x='slice',y=y_value,color='color_by',hover_data=['preview'],\n",
        "            title=f'{y_value} per {slice_length} words across {NOVEL_TITLE}',\n",
        "            height=444,\n",
        "            line_shape='hv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "57M_q6ezgOhc"
      },
      "source": [
        "#@title Show syntactic statistics\n",
        "#@todo ...\n",
        "printm('Todo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y2GRMvYvZPa"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "HMBLBppGLDGP"
      },
      "source": [
        "#@title Zip data\n",
        "PATH_ZIP=os.path.abspath(os.path.join(PATH_NOVEL,'..',NOVEL_TITLE+'.zip'))\n",
        "cmd=f'cd {PATH_NOVEL}/.. && zip -q -r9 {PATH_ZIP} {NOVEL_TITLE}'\n",
        "!{cmd}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "r8FykPAAvRTv"
      },
      "source": [
        "#@title Download zip file\n",
        "def dlzip(x): \n",
        "    from google.colab import files\n",
        "    files.download(PATH_ZIP)\n",
        "dlsize=os.path.getsize(PATH_ZIP)\n",
        "def human_size(bytes, units=[' bytes','KB','MB','GB','TB', 'PB', 'EB']):\n",
        "    \"\"\" Returns a human readable string representation of bytes \"\"\"\n",
        "    return str(bytes) + units[0] if bytes < 1024 else human_size(bytes>>10, units[1:])\n",
        "dlbutton=widgets.Button(description=f'Download zip ({human_size(dlsize)})')\n",
        "dlbutton.on_click(dlzip)\n",
        "dlbutton"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcYPpThaidSz"
      },
      "source": [
        "## Bibliography"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxxSd7UgmzsX"
      },
      "source": [
        "### Digital character networks\n",
        "\n",
        "\n",
        "* Sam Alexander, \"[Social Network Analysis and the Scale of Modernist Fiction](https://doi.org/10.26597/mod.0086)\", *Modernism/Modernity* 3.4 (2019)\n",
        "\n",
        "* David Bamman, Ted Underwood and Noah Smith, \"A Bayesian Mixed Effects Model of Literary Character,\" *ACL* 2014\n",
        "\n",
        "* David Elson, Nicholas Dames, Kathleen McKeown, \"[Extracting Social Networks from Literary Fiction](https://www.aclweb.org/anthology/P10-1015/)\", *Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics* (2010)\n",
        "\n",
        "* Vincent Labatut and Xavier Bost, \"[Extraction and Analysis of Fictional Character Networks: A Survey](https://doi.org/10.1145/3344548)\" (*ACM* 52.5.89,2019)\n",
        "\n",
        "* Graham Sack, “[Character Networks for Narrative Generation: Structural Balance Theory and the Emergence of Proto-Narratives](http://www.panstanford.com/books/9789814463263.html)” in *Complexity and the Human Experience: Modeling Complexity in the Humanities and Social Sciences* (ed. Paul A. Youngman and Mirsad Hadzikadic, Singapore: Pan Stanford Publishing, 2014)\n",
        "\n",
        "* Graham Sack, \"[Character networks for narrative generation](http://www.aaai.org/ocs/index.php/AIIDE/AIIDE12/paper/view/5550),\" in *Proceedings of the 8th Artificial Intelligence and Interactive Digital Entertainment Conference - Intelligent Narrative Technologies Workshop* (2012), 38-43."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPliHp3qm2yM"
      },
      "source": [
        "### Character network theory\n",
        "\n",
        "* Caroline Levine, *Forms: Whole, Rhythm, Hierarchy, Network* (Princeton, NJ: Princeton UP, 2015), 112ff\n",
        "\n",
        "* Anna Gibson, “Our Mutual Friend and Network Form”, *Novel: A Forum on Fiction* 48.1 (2015)\n",
        "\n",
        "* Franco Moretti, \"Network Theory, Plot Analysis\", *New Left Review* 68 (2011)\n",
        "\n",
        "* Alex Woloch, *The One vs. the Many: Minor Characters and the Space of the Protagonist in the Novel* (Princeton, NJ: Princeton UP, 2004)"
      ]
    }
  ]
}