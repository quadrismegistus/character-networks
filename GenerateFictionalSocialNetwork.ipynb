{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenerateFictionalSocialNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "deepnote_execution_queue": [
      {
        "cellId": "00022-ff1162c3-3948-446c-acce-872fcf60ab66",
        "msgId": "73eb9e42-25ad-494d-8c03-023ab23dea98",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00034-b9ad6142-6563-407b-8ad3-a5876477fb26",
        "msgId": "3b9245d5-400d-4a53-9f69-d444142a93bf",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00035-cdd7ccb4-7296-4719-84d3-472673cdc443",
        "msgId": "75989d45-0e9b-4593-8c10-1686e0c373e9",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00021-179cb35d-4648-4efe-b6fd-876394c1c59b",
        "msgId": "1f814d28-4415-499c-a5cd-a6e4d9ac736a",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00021-d2051519-3a82-404d-a7e5-14b9436441f5",
        "msgId": "a6e662db-c95a-47fa-8d8a-2654d9556ead",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00037-b3aca305-2ed6-4d42-bc87-876a8d26cf36",
        "msgId": "623407f1-3b90-4d5c-a810-1a26cce986eb",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00042-a368ff89-64fc-446c-ac88-4d18dbb9f670",
        "msgId": "f0d9a721-5c91-4fe8-bb23-b80f61da596f",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00043-3339a235-3919-4caf-99cc-1a82002c8cfd",
        "msgId": "b45ca3e1-fae9-427c-8ef4-97e14b9372b8",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00044-ffe3f92e-1831-4737-819c-594d7f266bbf",
        "msgId": "e5ed3a8a-8a14-43fb-9b36-14fbf7b1ef1a",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00045-8f2dd7bd-d30d-4761-af59-69d51830b25f",
        "msgId": "62e963bc-c939-4c56-80fb-d2c4bdb06c16",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00047-2df2d7bf-fb80-4929-9343-b0c6d00b3f9c",
        "msgId": "43d8f6ce-99ff-4fba-8e2c-f8957e42728d",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00029-9d653298-4df7-47ba-83ff-6493fbe0abcf",
        "msgId": "8b63bf8c-5095-4f62-b68f-b2fdb49e9386",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00031-56f64996-c2fc-4164-a0ec-49aed297359e",
        "msgId": "faace634-b48e-474c-8663-fc377b408b9a",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00050-5274092a-6201-46a3-bfb4-eb67bd65bd31",
        "msgId": "eba35fd2-6058-4ba0-96e3-6b207ee8551d",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00051-073607cb-b12a-4873-8b2d-10354f94a5b2",
        "msgId": "a8e38a75-d9e4-4c0e-97d9-b3c40eca049b",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00052-27236b40-a756-4940-bc7e-477dfebe1af7",
        "msgId": "d1fe4d10-9b6d-439b-a0e5-ed81632fbcde",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00053-23a8a9d7-bdad-41c7-96b8-fe50809a1f59",
        "msgId": "57cf6317-7164-4143-bcf1-78dbaceaa44b",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00037-60c48190-d1e0-4b63-9a2e-3c80a1fe8eaf",
        "msgId": "a16156b7-a1d1-4162-b3c4-be79e2903043",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00054-1bfcafff-7c9a-4153-8b83-31aa3f70993b",
        "msgId": "91327988-771f-4446-b125-3dd63a96549a",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00040-fca1c1e9-1fbe-4e41-b1e9-ac75fc1e4bb9",
        "msgId": "3b31a6b1-20b1-4c50-9dcb-162201ee2951",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00037-5cf01f7b-8451-4115-bccf-a00e972fd2d0",
        "msgId": "9d80a55c-385c-4a31-9bcf-b455f32bb92e",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00056-44d9d19f-8eee-433a-b143-bc2853ec1e0f",
        "msgId": "60dc4d9d-b3cd-4911-8906-07a8f297ef39",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00057-ce693ca1-3059-4fc3-bf1c-8729c5e08ec7",
        "msgId": "fc3a255d-8b69-429b-8000-3a5a20f95a23",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      },
      {
        "cellId": "00042-7bf65c2b-1cb9-4580-804f-d75e8016d3b1",
        "msgId": "a886f6d8-fdd8-49a7-aca2-9bf437b42968",
        "sessionId": "5e5db497-c6c9-4284-a1a3-1b4fa24de370"
      }
    ],
    "deepnote_notebook_id": "54fb2d49-2b86-41dc-a662-7cd8d1ba9b3e",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quadrismegistus/character-networks/blob/main/GenerateFictionalSocialNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpmp2cCY6PuW"
      },
      "source": [
        "# Generating character networks from novels and books"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agqnBkrz6Pub"
      },
      "source": [
        "### üèÉ‚Äç‚ôÄÔ∏è Starting up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCJ3UuDHZfO-",
        "cellView": "form"
      },
      "source": [
        "#@title üìö Choose a book to analyze\n",
        "#@markdown Enter the title of a book, along with a URL to a text file. To find a URL, search:\n",
        "#@markdown * [Project Gutenberg](https://gutenberg.org) for out of copyright texts\n",
        "#@markdown * [Z-lib](https://gutenberg.org) for in-copyright texts\n",
        "\n",
        "title = \"Pamela\" #@param {type:\"string\"}\n",
        "url = \"http://www.gutenberg.org/files/6124/6124-0.txt\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "\n",
        "#### Initial initial imports and settings\n",
        "import os,sys\n",
        "from google.colab import drive,files\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import Markdown, display\n",
        "# nicer print func\n",
        "def printm(x): display(Markdown(x))\n",
        "# elementary dirs\n",
        "PATH_ROOT='/content'\n",
        "PATH_LIB=os.path.join(PATH_ROOT,'lib')\n",
        "PATH_TMP=os.path.join(PATH_ROOT,'tmp')\n",
        "PATH_TMP_UPLOAD_FN_PRE=os.path.join(PATH_TMP,'uploaded_text')\n",
        "if not os.path.exists(PATH_ROOT): os.makedirs(PATH_ROOT)\n",
        "if not os.path.exists(PATH_LIB): os.makedirs(PATH_LIB)\n",
        "if not os.path.exists(PATH_TMP): os.makedirs(PATH_TMP)\n",
        "# add lib to python path\n",
        "sys.path.insert(0,PATH_LIB)\n",
        "\n",
        "# offer button as well\n",
        "def upload_f(x,tmpfnpre=PATH_TMP_UPLOAD_FN_PRE):\n",
        "    from google.colab import files\n",
        "    res = files.upload()\n",
        "    fn=list(res.keys())[0]\n",
        "    fnpre,fnext=os.path.splitext(fn)\n",
        "    tmpfn=tmpfnpre+fnext\n",
        "    !mv \"$fn\" \"$tmpfn\"\n",
        "\n",
        "printm('### Alternatively to a URL, you can upload a file (txt, epub, pdf, docx, ...)')\n",
        "ubutton = widgets.Button(description=\"Upload text\")\n",
        "ubutton.on_click(upload_f)\n",
        "display(ubutton)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bkgSHUa6JAi",
        "cellView": "form"
      },
      "source": [
        "#@title üìÇ Choose where to store data\n",
        "#@markdown ##### Save text data to Google drive?\n",
        "#@markdown <small>This will save all generated data to your Google Drive, making downloading/uploading annotations and other data unnecessary. If yes, specify a directory path relative to your root Drive folder.</small>\n",
        "save = \"Yes, save in Google Drive\" #@param [\"Yes, save in Google Drive\", \"No, keep on temporary storage\"]\n",
        "path = \"DigHum/CharacterNetworks\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cGcIoAzPP8B",
        "cellView": "form"
      },
      "source": [
        "#@title Once you are done, click on menu item **Runtime > Run all**\n",
        "\n",
        "printm('#### Checking input')\n",
        "# Load widget code\n",
        "# Valid input?\n",
        "class InvalidInput(Exception):\n",
        "    def _render_traceback_(self): pass\n",
        "NOVEL_URL=url\n",
        "NOVEL_TITLE_NICE=title.strip()\n",
        "NOVEL_TITLE=NOVEL_TITLE_NICE.title().replace(' ','')\n",
        "if not NOVEL_TITLE:\n",
        "    print('Type a title in the box above')\n",
        "    raise InvalidInput\n",
        "else:\n",
        "    printm(f'* Using title: **{NOVEL_TITLE_NICE}**')\n",
        "    printm(f'* Using filename: **{NOVEL_TITLE}**')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PATH_TOOLS=os.path.join('/content','tools')\n",
        "PATH_NOVELS=os.path.join(PATH_ROOT,'texts')\n",
        "PATH_TO_BOOKNLP=os.path.join(PATH_TOOLS,'book-nlp')\n",
        "URL_CORENLP='http://nlp.stanford.edu/software/stanford-corenlp-4.1.0.zip'\n",
        "MODEL_FN='stanford-corenlp-4.1.0-models.jar'\n",
        "PATH_TO_BOOKNLP_BINARY=os.path.abspath(os.path.join(PATH_TO_BOOKNLP,'runjava'))\n",
        "PATH_NOVEL=os.path.join(PATH_NOVELS,NOVEL_TITLE)\n",
        "ofn_novel=os.path.join(PATH_NOVEL,f'{NOVEL_TITLE}.txt')\n",
        "ofn=os.path.join(PATH_NOVEL,f'data.parses.{NOVEL_TITLE}.jsonl')\n",
        "ofn_meta=os.path.join(PATH_NOVEL,f'data.charmeta.{NOVEL_TITLE}.csv')\n",
        "ofn_meta_anno=os.path.join(PATH_NOVEL,f'data.charmeta.{NOVEL_TITLE}.anno.csv')\n",
        "ofn_booknlp_out=os.path.splitext(ofn_novel)[0]+'.booknlp'\n",
        "ofn_booknlp_toks=os.path.join(ofn_booknlp_out,'tokens.txt')\n",
        "ofn_fig_dir=os.path.join(PATH_NOVEL,'imgs')\n",
        "ofn_gif=os.path.join(PATH_NOVEL,'anim.gif')\n",
        "ofn_mp4=os.path.join(PATH_NOVEL,'anim.mp4')\n",
        "printm(f'* Path to novel data set to: **{PATH_NOVEL}**')\n",
        "####\n",
        "\n",
        "# set up symlinks\n",
        "if save:\n",
        "    PATH_ROOT_DRIVE=os.path.join('/content/drive','My Drive',path)\n",
        "    if not os.path.exists(PATH_ROOT_DRIVE): os.makedirs(PATH_ROOT_DRIVE)\n",
        "    PATH_NOVELS_DRIVE=os.path.join(PATH_ROOT_DRIVE,'texts')\n",
        "    if not os.path.exists(PATH_NOVELS):\n",
        "        #@todo what if user changes mind about gdrive?\n",
        "        os.symlink(PATH_NOVELS_DRIVE, PATH_NOVELS)\n",
        "    printm(f'* Linking: {PATH_NOVELS} --> **{PATH_NOVELS_DRIVE}**')\n",
        "if not os.path.exists(PATH_NOVEL): os.makedirs(PATH_NOVEL)\n",
        "if not os.path.exists(PATH_TOOLS): os.makedirs(PATH_TOOLS)\n",
        "\n",
        "\n",
        "### getting text using code from a gist\n",
        "!pip install bs4 kitchen wget fulltext epub-conversion pymupdf requests xml_cleaner html2text -q -q\n",
        "import urllib.request\n",
        "gisturl='https://gist.githubusercontent.com/quadrismegistus/f76c2ffcccedc496a638ca430b6851ab/raw/ede9744a01adc324a6223b924789f1553853f91c/brute_txt.py'\n",
        "urllib.request.urlretrieve(gisturl,os.path.join(PATH_LIB,'brute_txt.py'))\n",
        "from brute_txt import brute\n",
        "\n",
        "# is uploaded file?\n",
        "tmp_fns=os.listdir(PATH_TMP)\n",
        "matches=[tmp_fn for tmp_fn in tmp_fns if tmp_fn.startswith(os.path.basename(PATH_TMP_UPLOAD_FN_PRE))]\n",
        "if any(matches):\n",
        "    match=matches[0]\n",
        "    matchpath=os.path.join(PATH_TMP,match)\n",
        "    printm(f'* Loading text from uploaded file: {match}')\n",
        "    NOVEL_TXT=brute(matchpath)\n",
        "    os.remove(matchpath)\n",
        "elif url:\n",
        "    printm(f'* Loading text from URL: {url}')\n",
        "    NOVEL_TXT=brute(url)\n",
        "else:\n",
        "    printm('No uploaded file nor URL to file')\n",
        "    raise InvalidInput\n",
        "# save text\n",
        "if not NOVEL_TXT:\n",
        "    printm('Empty text')\n",
        "    raise InvalidInput\n",
        "else:\n",
        "    printm(f'* Loaded book with **{len(NOVEL_TXT.strip().split())}** words')\n",
        "    with open(ofn_novel,'w') as of: of.write(NOVEL_TXT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Gweu3r7TUY"
      },
      "source": [
        "## üî© Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsTueiv-vRSa",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "!pip install dynetx fa2 pandas colour dimcli numpy moviepy ffmpeg pyvis networkx gender-guesser imageio-ffmpeg imageio -q\n",
        "\n",
        "\n",
        "#@title Import modules\n",
        "# imports\n",
        "import os,sys\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import dynetx as dn\n",
        "from collections import Counter\n",
        "from shutil import which\n",
        "from colour import Color\n",
        "import numpy as np\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual, widgets\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import math,os\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import plotly.express as px\n",
        "pd.options.display.max_rows=25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWFNAPDd-1T_",
        "cellView": "form"
      },
      "source": [
        "#@title Install Booknlp\n",
        "os.chdir(PATH_TOOLS)\n",
        "if not os.path.exists(PATH_TO_BOOKNLP):\n",
        "    !git clone https://github.com/dbamman/book-nlp\n",
        "PATH_BOOKNLP_MODELS=os.path.join(PATH_TO_BOOKNLP,'lib',MODEL_FN)\n",
        "if not os.path.exists(PATH_BOOKNLP_MODELS):\n",
        "    !wget $URL_CORENLP\n",
        "    corenlp_fn=URL_CORENLP.split('/')[-1]\n",
        "    corenlp_dir=f'{corenlp_fn.split(\".zip\")[0]}'\n",
        "    !unzip -q \"$corenlp_fn\"\n",
        "    ifnfn=f'{corenlp_fn.split(\".zip\")[0]}/{MODEL_FN}'\n",
        "    !mv \"$ifnfn\" \"$PATH_BOOKNLP_MODELS\"\n",
        "    !rm \"$corenlp_fn\"\n",
        "    !rm -rf \"$corenlp_dir\"\n",
        "os.chdir(PATH_ROOT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX3W6A726Puv"
      },
      "source": [
        "## üî® Parse\n",
        "\n",
        "This will take ~15 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ82a6Dn6Puy",
        "cellView": "form"
      },
      "source": [
        "#@title Parse text using BookNLP\n",
        "def parse_text(path_txt):\n",
        "    if not path_txt: return    \n",
        "    path_out=ofn_booknlp_out\n",
        "    path_toks=ofn_booknlp_toks\n",
        "    cmd=f'cd \"{PATH_TO_BOOKNLP}\" && ./runjava novels/BookNLP -doc {path_txt} -printHTML -p {path_out} -tok {path_toks} -f'\n",
        "    # print('>>',cmd)\n",
        "    !{cmd} #os.system(cmd)\n",
        "    os.rename(os.path.join(path_out,'book.id.html'), os.path.join(path_out,'parsed.html'))\n",
        "    os.rename(os.path.join(path_out,'book.id.book'), os.path.join(path_out,'parsed.json'))\n",
        "\n",
        "#@title\n",
        "# Parse! This will take 10-15 minutes for most novels... time to make coffee?\n",
        "if not os.path.exists(ofn_booknlp_toks): parse_text(ofn_novel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQR_q3tZvRSz"
      },
      "source": [
        "## ü§î Examine results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrb5Am8n6PvQ",
        "cellView": "form"
      },
      "source": [
        "#@title Load generated character metadata\n",
        "def read_parsed_json(path_parsed_json):\n",
        "    import json,os\n",
        "    from collections import defaultdict,Counter\n",
        "    #json.loads(path_parsed_json)\n",
        "    dat=json.load(open(path_parsed_json))\n",
        "    keys=[]\n",
        "    nullchar=defaultdict(Counter)\n",
        "    text_id=path_parsed_json.split('/')[-3]\n",
        "    for char in dat['characters']:\n",
        "        if not char['names']: continue\n",
        "        names=[x['n'] for x in char['names']]\n",
        "        \n",
        "        chardx={'name':names[0], 'id':char['id'], 'names':', '.join(names), 'text_id':text_id}\n",
        "        num=0\n",
        "        for key in ['agent','patient','poss','mod','speaking']:\n",
        "            chardx['num_'+key]=len(char[key])\n",
        "            num+=chardx['num_'+key]\n",
        "            # chardx['words_'+key]=words=[]\n",
        "            # for event in char[key]:\n",
        "            #     if 'w' in event:\n",
        "            #         wtxt=event['w']\n",
        "            #         wlist=word_tokenize(wtxt) if ' ' in wtxt else [wtxt]\n",
        "            #         wlist=[w.lower() for w in wlist if w and w[0].isalpha()]\n",
        "            #         words+=wlist\n",
        "        num+=1\n",
        "        chardx['num']=num\n",
        "        yield chardx\n",
        "\n",
        "# Load jsons into character metadata\n",
        "char_jsons=list(read_parsed_json(os.path.join(ofn_booknlp_out,'parsed.json')))\n",
        "char_df=pd.DataFrame(char_jsons)\n",
        "id2name=dict(zip(char_df.id,char_df.name))\n",
        "printm(f'Found **{len(char_jsons)}** characters, for a total of **{sum(char_df.num)}** mentions.')\n",
        "topn=10\n",
        "printm(f'#### Top {topn} characters')\n",
        "char_df.sort_values('num',ascending=False)[['name','num','names']].head(topn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2BjLU20Hxvy",
        "cellView": "form"
      },
      "source": [
        "#@title Load word-by-word parse data\n",
        "# load and gen\n",
        "tok_df=pd.read_csv(ofn_booknlp_toks,sep='\\t')\n",
        "tok_df['isChar']=tok_df['characterId'].apply(lambda x: int(x!=-1))\n",
        "tok_df['isWord']=1\n",
        "\n",
        "# show\n",
        "printm(f'* Number of words {len(tok_df)} words')\n",
        "printm(f'* Number of sentences {len(set(tok_df.sentenceID))} words')\n",
        "printm(f'* Number of paragraphs: {len(set(tok_df.paragraphId))}')\n",
        "printm(f'* Number of character mentions: {sum(tok_df.isChar)}')\n",
        "# tok_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfZAMbM56PvX",
        "cellView": "form"
      },
      "source": [
        "#@title Prepare metadata for manual annotation\n",
        "if 1:# not os.path.exists(ofn_meta):\n",
        "    # Guess gender of characters?\n",
        "    import gender_guesser.detector as gender\n",
        "    gd = gender.Detector()\n",
        "\n",
        "    prefix_clues={\n",
        "        'female':{'Ms.', 'Ms ','Mrs.','Mrs ','Miss ','Madame','Mme.','Mme ','Signorina','Maestra '},\n",
        "        'male':{'Don ','Signor ','Mr.','Mr ','Maestro '}\n",
        "    }\n",
        "\n",
        "    def guess_gender(name,gd=gd):\n",
        "        if not name: return None\n",
        "\n",
        "        for gndr,prfxs in prefix_clues.items():\n",
        "            for p in prfxs:\n",
        "                if name.startswith(p):\n",
        "                    return gndr\n",
        "        \n",
        "        gend=gd.get_gender(name).replace('mostly_','')\n",
        "        return gend\n",
        "    char_df['gender']=char_df.name.apply(guess_gender)\n",
        "    dfm=char_df#.groupby(['name','gender','id']).sum().reset_index()\n",
        "\n",
        "    # create other fields\n",
        "    dfm['name_real']=dfm['name']\n",
        "    dfm['other']=''\n",
        "    dfm['notes']=''\n",
        "    dfm['race']=''\n",
        "    dfm['class']=''\n",
        "    dfm_save=dfm[['id','name','name_real','num','gender','race','class','other','notes']].sort_values('num',ascending=False)\n",
        "    dfm_save.to_csv(ofn_meta,index=False)\n",
        "    # if not os.path.exists(ofn_meta_anno):\n",
        "        # dfm_save.to_csv(ofn_meta_anno,index=False)\n",
        "    printm('#### Metadata generated automatically')\n",
        "    display(dfm_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDekpVyGCokK",
        "cellView": "form"
      },
      "source": [
        "#@title Download metadata for manual annotation\n",
        "from google.colab import files\n",
        "def download_anno(x):\n",
        "    files.download(ofn_meta)\n",
        "dbutton = widgets.Button(description=\"Download as CSV\")\n",
        "dbutton.on_click(download_anno)\n",
        "printm('''Open in a spreadsheet editor (e.g. excel) and change the names\n",
        "in the column 'name_real'to rename the character.\n",
        "Delete the name there to declare that character name invalid.\n",
        "The other columns allow you to set variables to color or size the networks by.\n",
        "''')\n",
        "display(dbutton)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4r5sEzq6Pvo",
        "cellView": "form"
      },
      "source": [
        "#@title Upload manually refined character metadata \n",
        "printm('''Open in a spreadsheet editor (e.g. excel) and change the names\n",
        "in the column 'name_real'to rename the character.\n",
        "Delete the name there to declare that character name invalid.\n",
        "The other columns allow you to set variables to color or size the networks by.\n",
        "\n",
        "When you're done, click \"Upload\" and upload the new CSV below.\n",
        "If you saved your sheet as an excel file, export it as CSV before uploading.\n",
        "''')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def upload_anno(x):\n",
        "    FILES = files.upload()\n",
        "    if not FILES: return\n",
        "    fn=list(FILES.keys())[0]\n",
        "    fnpre,ext=os.path.splitext(fn)\n",
        "    if ext not in {'.csv'}:\n",
        "        print('File must be a CSV file. (e.g. In excel, export as CSV.)')\n",
        "        raise InvalidInput\n",
        "    !mv \"$fn\" \"$ofn_meta_anno\"\n",
        "\n",
        "\n",
        "button = widgets.Button(description=\"Upload annotations\")\n",
        "button.on_click(upload_anno)\n",
        "display(button)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QedvKrFk6Pvv",
        "cellView": "form"
      },
      "source": [
        "#@title Reload and filter metadata\n",
        "# load csv\n",
        "\n",
        "min_num_mentions=widgets.IntSlider(min=1,max=50,value=5)\n",
        "printm('### Filter by the minimum number of mentions')\n",
        "\n",
        "@interact\n",
        "def filter_metadata(min_num_mentions=min_num_mentions):\n",
        "    ifn=ofn_meta_anno if os.path.exists(ofn_meta_anno) else ofn_meta\n",
        "    dfm=pd.read_csv(ifn).fillna('').rename(columns={'num':'num_total', 'count':'num_total', 'name_standardized':'name_real'})\n",
        "    dfm=dfm[(dfm.name_real.apply(lambda x: x[0].isalpha()))] \n",
        "    name2real=dict(zip(dfm.name,dfm.name_real))\n",
        "    dfmr=dfm.rename(columns={'id':'characterId'})\n",
        "    dfmr=dfmr[dfmr.num_total>=min_num_mentions]\n",
        "    return dfmr.sort_values('num_total')#[dfmr.name.str.startswith('Don')] #.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG-0CIs7Lv3c"
      },
      "source": [
        "## Analyze results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mVzRxGOWP6o",
        "cellView": "form"
      },
      "source": [
        "#@title Distribution of character attention\n",
        "# create\n",
        "dfm=filter_metadata(min_num_mentions=min_num_mentions.value)\n",
        "all_df=dfm.merge(tok_df,on='characterId',how='right').fillna('')\n",
        "color_by=list(dfm.columns)[list(dfm.columns).index('gender'):]+['none']\n",
        "dfm['none']='none'\n",
        "# res=char_df.num.plot(kind='density',width=666)\n",
        "widg_colorby=widgets.Dropdown(options=color_by,description='Group by')\n",
        "num_top_chars=widgets.IntSlider(min=5,max=len(dfm)+5,step=5,value=25,description='# Top Chars')\n",
        "\n",
        "@interact\n",
        "def showtopn(num_top=num_top_chars):\n",
        "    n=num_top\n",
        "    printm(f'#### Median number of mentions per character (all): {int(dfm.num_total.median())}')\n",
        "    return px.bar(\n",
        "        dfm.sort_values('num_total',ascending=True).iloc[-n:],\n",
        "        y=\"name_real\",\n",
        "        x=\"num_total\",\n",
        "        hover_data=['name_real','num_total','gender'],\n",
        "        title=f'Distribution of mentions over top {n} characters',\n",
        "        text='num_total',\n",
        "        width=666,\n",
        "        height=666/25 * n,\n",
        "        orientation='h'\n",
        "    )    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKGTMMtZDqm6",
        "cellView": "form"
      },
      "source": [
        "#@title Distribution of attention by group\n",
        "@interact\n",
        "def show_histogram(group_by=widg_colorby):\n",
        "    \n",
        "\n",
        "    printm(f'### Distribution by {group_by}')\n",
        "    #if group_by!='none':\n",
        "    xvals=[]\n",
        "    for cat,catdf in sorted(dfm.groupby(group_by),key=lambda x: -len(x[1])):\n",
        "        totalperc=round(sum(catdf.num_total)/sum(dfm.num_total)*100,1)\n",
        "        printm(f'#### {len(catdf)} {cat} characters make up {totalperc}% of all mentions')\n",
        "        # printm(f'* Median number of mentions per character ({cat}): {int(catdf.num_total.median())}')\n",
        "        stats=[f'{row.name_real} ({row.num_total})' for i,row in catdf.sort_values('num_total',ascending=False).iterrows()]\n",
        "        printm(f'''* {', '.join(stats)} [median={int(catdf.num_total.median())}]''')\n",
        "        xvals+=[cat]\n",
        "    \n",
        "    # display(px.histogram(dfm, x='num_total', color=group,marginal='rug')\n",
        "\n",
        "    fig=px.box(\n",
        "        dfm.sort_values(group_by),\n",
        "        y=\"num_total\",\n",
        "        range_y=(.9,max(dfm.num_total)),\n",
        "        log_y=True,\n",
        "        x=group_by,\n",
        "        width=666,\n",
        "        color=group_by,\n",
        "        points=\"all\",\n",
        "        hover_data=[x for x in ['name_real','num_total'] + color_by if x!='none'],\n",
        "        title=f'Number of mentions for characters by {group_by}'\n",
        "    )\n",
        "\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57M_q6ezgOhc",
        "cellView": "form"
      },
      "source": [
        "#@title Show syntactic statistics\n",
        "#@todo ...\n",
        "printm('Todo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVMhWhGz6Pvy"
      },
      "source": [
        "## üï∏ Generate social network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od-kOfW0sucL",
        "cellView": "form"
      },
      "source": [
        "#@title Generate dynamic network from interactions\n",
        "NET_STATS=['degree','degree_centrality','betweenness_centrality','eigenvector_centrality','closeness_centrality']\n",
        "slice_length=widgets.Dropdown(options=[1,5,10,50,100,250,500,1000,2000,5000,10000,25000],value=500,description='Length')\n",
        "time_slider1=widgets.IntSlider(min=ts[0], max=ts[-1], step=10, value=ts[0])\n",
        "time_slider2=widgets.IntSlider(min=ts[0], max=ts[-1], step=10, value=ts[-1])\n",
        "weight_slider=widgets.IntSlider(min=1, max=10, step=1, value=2)\n",
        "mindegree_slider=widgets.IntSlider(min=0, max=10, step=1, value=1)\n",
        "weight_factor=widgets.IntSlider(min=1, max=100, step=1, value=5)\n",
        "time_units=dict([('words','tokenId'), ('sentences','sentenceID'), ('paragraphs','paragraphId')])\n",
        "time_type=widgets.Dropdown(options=list(time_units.keys()),description='Unit of time',value='words')\n",
        "\n",
        "def make_dyn_charnet(name_key=fixed('name_real'),t_unit='words',slice_length=1000):\n",
        "    roundby=slice_length\n",
        "    t_key=time_units.get(t_unit,'tokenId')\n",
        "    printm(f'* Divide text every {roundby} {t_unit}')\n",
        "\n",
        "    from tqdm import tqdm\n",
        "    # init\n",
        "    dg = dn.DynGraph(edge_removal=False)\n",
        "    all_df['slice']=all_df[t_key].apply(lambda x: x//roundby)\n",
        "    \n",
        "    # t=paragraph\n",
        "    last_char=None\n",
        "    ts=set()\n",
        "    t=0\n",
        "    edges=set()\n",
        "    name2real=dict(zip(all_df.name, all_df.name_real))\n",
        "\n",
        "    grps=sorted(list(all_df.groupby('slice')))\n",
        "    grp_ld=[]\n",
        "    edge_list=[]\n",
        "    for sl,sldf in grps:\n",
        "        t=sl\n",
        "        chars_in_slice=[x for x in sorted(list(set(sldf[name_key]))) if x]\n",
        "        #printm(f' * At t={t}, found {len(chars_in_slice)} unique characters: {\", \".join(chars_in_slice)}')\n",
        "        for a in chars_in_slice:\n",
        "            for b in chars_in_slice:\n",
        "                if b<=a: continue\n",
        "                dg.add_interaction(u=a,v=b,t=t)\n",
        "                edge_list.append((t,a,b))\n",
        "        grp_dx={\n",
        "            't':t,\n",
        "            'chars':chars_in_slice,\n",
        "            'num_chars':len(chars_in_slice),\n",
        "        }\n",
        "        grp_ld.append(grp_dx)\n",
        "    grp_df=pd.DataFrame(grp_ld)\n",
        "\n",
        "    # show stats\n",
        "    ts=dg.temporal_snapshots_ids()\n",
        "    chartups_dyn={tuple(sorted([u,v])+[t]) for (u, v, op, t) in dg.stream_interactions()}\n",
        "    chartups_stat={tuple(sorted([u,v])) for (u, v, op, t) in dg.stream_interactions()}\n",
        "    printm(f'* {len(ts)} time slices')\n",
        "    printm(f'* {len(chartups_stat)} unique character-to-character edges')\n",
        "    printm(f'* {len(charnet_dynamic_edgelist)} total interactions')\n",
        "    display(grp_df)\n",
        "    return dg,grp_df,edge_list\n",
        "\n",
        "# show opts\n",
        "charnet_dynamic_i=interactive(\n",
        "    make_dyn_charnet,\n",
        "    t_unit=time_type,\n",
        "    slice_length=slice_length\n",
        ")\n",
        "charnet_dynamic_i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI33o-pKFwHm",
        "cellView": "form"
      },
      "source": [
        "#@title Show character density across length of text\n",
        "# Other token stats\n",
        "yopts=widgets.Dropdown(options=[('# of mentions','num_mentions'),('# of unique','num_chars')], desription='Y value')\n",
        "\n",
        "@interact\n",
        "def show_density(slice_length=slice_length,color_by=widg_colorby,y_value=yopts):\n",
        "    num_words_in_preview=30\n",
        "    slice2txt=defaultdict(list)\n",
        "    all_df['slice']=all_df.tokenId.apply(lambda x: x//slice_length*slice_length)\n",
        "    all_df['none']='none'\n",
        "    slice_ld=[]\n",
        "    for sl,sldf in all_df.groupby('slice'):\n",
        "        slice_dx={'slice':sl}\n",
        "        # get preview\n",
        "        slice_dx['preview']=[]\n",
        "        for i,row in sldf.iterrows():\n",
        "            if not str(row['originalWord']).strip(): continue\n",
        "            if len(slice_dx['preview'])>num_words_in_preview:break\n",
        "            slice_dx['preview']+=[str(row['originalWord']).strip()+str(' ' if row['whitespaceAfter']=='S' else '')]\n",
        "        slice_dx['preview']=''.join(slice_dx['preview'])+'...'\n",
        "        # count by category\n",
        "        num_words=len(sldf)\n",
        "        for cat,catdf in sldf.groupby(color_by):\n",
        "            num_mentions=sum(catdf['isChar'])\n",
        "            num_chars=len(set(catdf['characterId']))\n",
        "            slice_cat_dx=dict(**slice_dx, **{'color_by':cat, 'num_mentions':num_mentions, 'num_chars':num_chars, 'color_by':cat})\n",
        "            slice_ld.append(slice_cat_dx)\n",
        "\n",
        "    slicedf=pd.DataFrame(slice_ld)\n",
        "    printm(f'Median number of unique characters = **{slicedf.num_chars.median()}** names per {slice_length} words')\n",
        "    printm(f'Median number of character mentions = **{slicedf.num_mentions.median()}** names per {slice_length} words')\n",
        "\n",
        "\n",
        "    import plotly.express as px\n",
        "    return px.line(slicedf,x='slice',y=y_value,color='color_by',hover_data=['preview'],\n",
        "            title=f'{y_value} per {slice_length} words across {NOVEL_TITLE}',\n",
        "            height=444,\n",
        "            line_shape='hv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoEVy5HkotKl"
      },
      "source": [
        "##  üìê Fine tune network parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP6AxCqFg6Nw",
        "cellView": "form"
      },
      "source": [
        "#@title Convert to static network\n",
        "# Convert to static\n",
        "\n",
        "\n",
        "def to_static(edge_list,t_start=None,t_end=None,min_weight=2,name_key='name_real',stats=NET_STATS,min_degree=1):\n",
        "    # printm(f'#### Generating static network with minimum weight set to {min_weight}')\n",
        "    import networkx as nx\n",
        "    g=nx.Graph()\n",
        "\n",
        "    num_interactions_d=Counter()\n",
        "    for t,u,v in sorted(edge_list):\n",
        "        if t_start and t<t_start: continue\n",
        "        if t_end and t>t_end: continue\n",
        "        num_interactions_d[u]+=1\n",
        "        num_interactions_d[v]+=1\n",
        "        if not g.has_edge(u,v):\n",
        "            g.add_edge(u,v,t=[t],weight=1)\n",
        "        else:\n",
        "            g[u][v]['weight']+=1\n",
        "            g[u][v]['t']+=[t]\n",
        "\n",
        "    if min_weight:\n",
        "        for a,b,d in list(g.edges(data=True)):\n",
        "            if d['weight']<min_weight:\n",
        "                g.remove_edge(a,b)\n",
        "\n",
        "    # add metadata\n",
        "    for n in g.nodes():\n",
        "        # print(n,'??')\n",
        "        ndf=dfm[dfm.name_real==n]\n",
        "        ncdf=ndf.mode()\n",
        "        # print(n,len(ncdf))\n",
        "        common_d=dict(ncdf.iloc[0])\n",
        "        for k,v in common_d.items(): g.nodes[n][k]=v\n",
        "        g.nodes[n]['num_interactions']=num_interactions_d[n]\n",
        "        g.nodes[n]['num_mentions']=ndf['num_total'].sum() #.iloc[0]['num_total']\n",
        "\n",
        "    # include node stats\n",
        "    for stat in stats:\n",
        "        try:\n",
        "            func=getattr(nx,stat)\n",
        "            for n,v in dict(func(g)).items():\n",
        "                g.nodes[n][stat]=v\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # return graph\n",
        "    if min_degree:\n",
        "        for n in list(g.nodes()):\n",
        "            if g.nodes[n]['degree']<min_degree:\n",
        "                g.remove_node(n)\n",
        "\n",
        "    return g\n",
        "\n",
        "\n",
        "#@title\n",
        "def layout(g):\n",
        "    from fa2 import ForceAtlas2\n",
        "    forceatlas2 = ForceAtlas2(\n",
        "        # Behavior alternatives\n",
        "        outboundAttractionDistribution=True,  # Dissuade hubs\n",
        "        linLogMode=False,  # NOT IMPLEMENTED\n",
        "        adjustSizes=False,  # Prevent overlap (NOT IMPLEMENTED)\n",
        "        edgeWeightInfluence=1.0,\n",
        "\n",
        "        # Performance\n",
        "        jitterTolerance=1.0,  # Tolerance\n",
        "        barnesHutOptimize=True,\n",
        "        barnesHutTheta=1.2,\n",
        "        multiThreaded=False,  # NOT IMPLEMENTED\n",
        "\n",
        "        # Tuning\n",
        "        scalingRatio=2.0,\n",
        "        strongGravityMode=False,\n",
        "        gravity=1.0,\n",
        "\n",
        "        # Log\n",
        "        verbose=False\n",
        "    )\n",
        "    \n",
        "    pos = forceatlas2.forceatlas2_networkx_layout(g, pos=None, iterations=2000)\n",
        "    return pos\n",
        "\n",
        "\n",
        "#@title Drawing static networks\n",
        "def drawnet_nx(g,ofn='net.png',pos=None,weight_factor=1,size_by='degree',size_factor=1000,save=True,title=None,color_by=None,default_color='gray',color_start='red',color_end='blue',default_size=300):\n",
        "    from matplotlib import pyplot as plt\n",
        "    fig = plt.figure(figsize=(10,10))#,facecolor=(0, 0, 0))\n",
        "    if title: fig.suptitle(title, fontsize=16)\n",
        "    nodelist=g.nodes()\n",
        "    labels=dict((n,n) for n in nodelist)\n",
        "    try:\n",
        "        size_vals=x=np.array([g.nodes[n].get(size_by,np.nan) for n in nodelist])\n",
        "        normalized = (x-min(x))/(max(x)-min(x))\n",
        "        node_size=[x*size_factor if x is not np.nan else default_size for x in normalized]\n",
        "    except:\n",
        "        node_size=default_size\n",
        "    node_color=[]\n",
        "\n",
        "    edgelist=list(g.edges())\n",
        "    edge_size=[g[a][b]['weight']*weight_factor for a,b in edgelist]\n",
        "    try:\n",
        "        edge_size_vals=x=np.array([g[a][b]['weight'] for a,b in edgelist])\n",
        "        edge_normalized = (x-min(x))/(max(x)-min(x))\n",
        "        edge_size=[x*weight_factor if x is not np.nan else 1 for x in edge_normalized]\n",
        "    except:\n",
        "        edge_size=1\n",
        "\n",
        "\n",
        "    if color_by:\n",
        "        color_types=sorted(list(set(g.nodes[n][color_by] for n in g.nodes())))\n",
        "        num_colors=len(color_types)\n",
        "        spectrum=list(Color(color_start).range_to(Color(color_end),num_colors))\n",
        "        colormap=dict(zip(color_types, spectrum))\n",
        "        node_color=[colormap[g.nodes[n][color_by]].hex for n in g.nodes()]\n",
        "    else:\n",
        "        node_color=default_color\n",
        "\n",
        "    nx.draw_networkx(\n",
        "        g,\n",
        "        pos=pos,\n",
        "        labels=labels,\n",
        "        nodelist=nodelist,\n",
        "        node_size=node_size,\n",
        "        edgelist=edgelist,\n",
        "        width=edge_size,\n",
        "        font_color='black',\n",
        "        font_weight='bold',\n",
        "        font_size=12,\n",
        "        node_color=node_color,\n",
        "        edge_color='teal'\n",
        "    )\n",
        "    if save:\n",
        "        plt.savefig(ofn)\n",
        "        plt.close()\n",
        "    else:\n",
        "        return plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate\n",
        "printm('### Set minimum weight')\n",
        "# display(weight_slider)\n",
        "\n",
        "# @interact\n",
        "def make_static(min_weight=weight_slider):\n",
        "    # get current data \n",
        "    charnet_dynamic,charnet_dynamic_df,charnet_dynamic_edgelist=charnet_dynamic_i.result\n",
        "    dg=charnet_dynamic\n",
        "\n",
        "    charnet_static=g=to_static(charnet_dynamic_edgelist,min_weight=min_weight)\n",
        "    printm(f'Graph generated with {g.order()} nodes and {g.size()} edges')\n",
        "    charnet_static_df=pd.DataFrame(dict(charnet_static.nodes[n]) for n in charnet_static.nodes())\n",
        "    charnet_static_df_edges=pd.DataFrame({'source':a, 'target':b, **d} for a,b,d in charnet_static.edges(data=True))    \n",
        "    \n",
        "    printm('### Edge data')\n",
        "    display(charnet_static_df_edges.sort_values('weight',ascending=False))\n",
        "\n",
        "    # printm('### Node data')\n",
        "    # display(charnet_static_df.sort_values('num_total',ascending=False))\n",
        "    printm('### Graph preview')\n",
        "    pos=layout(g)\n",
        "    title=f'{NOVEL_TITLE_NICE} (w>={min_weight})'\n",
        "    try:\n",
        "        drawnet_nx(\n",
        "            g,\n",
        "            save=False,\n",
        "            pos=pos,\n",
        "            title=title,\n",
        "            weight_factor=10\n",
        "        )\n",
        "    except ValueError:\n",
        "        pass\n",
        "    return charnet_static, charnet_static_df, charnet_static_df_edges\n",
        "\n",
        "charnet_static_i=interactive(make_static,min_weight=weight_slider)\n",
        "charnet_static_i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnrvgwoL3ICh",
        "cellView": "form"
      },
      "source": [
        "#@title Fiddle with settings\n",
        "widg_sizeby=widgets.Dropdown(options=sorted(list(NET_STATS)))\n",
        "# charnet_static,charnet_static_df=charnet_static_i.result\n",
        "# node_features=set(charnet_static_df.select_dtypes('number').columns) - {'id'}\n",
        "\n",
        "\n",
        "def show_graph(t_start=time_slider1,\n",
        "               t_end=time_slider2,\n",
        "               min_weight=weight_slider,\n",
        "               color_by=widg_colorby,\n",
        "               size_by=widg_sizeby,\n",
        "               weight_factor=weight_factor):\n",
        "    g=to_static(charnet_dynamic,min_weight=min_weight)\n",
        "    pos=layout(g)\n",
        "    g_sofar=to_static(dg.time_slice(t_from=t_start,t_to=t_end),min_weight=min_weight)\n",
        "    sized=nx.betweenness_centrality(g_sofar)\n",
        "    title=f'{NOVEL_TITLE} (t={t_start}-{t_end}) (w>={min_weight})'\n",
        "    try:\n",
        "        drawnet_nx(\n",
        "            g_sofar,\n",
        "            save=False,\n",
        "            pos=pos,\n",
        "            size_by=widg_sizeby.value,\n",
        "            color_by=widg_colorby.value,\n",
        "            weight_factor=weight_factor,\n",
        "            title=title\n",
        "        )\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "\n",
        "graph_configurator = interactive(show_graph)\n",
        "graph_configurator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErumNfe105wv"
      },
      "source": [
        "## üé• Generating dynamic network visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP79AxUY6Pv-",
        "cellView": "form"
      },
      "source": [
        "#@title Generate underlying images\n",
        "def drawnets(dg=dg,odir=ofn_fig_dir):\n",
        "    if not os.path.exists(odir): os.makedirs(odir)\n",
        "    g=to_static(dg)\n",
        "    #pos=nx.spring_layout(g,k=5/math.sqrt(g.order()))\n",
        "    pos=layout(g)\n",
        "    for t in tqdm(dg.temporal_snapshots_ids()):\n",
        "        cg=to_static(dg.time_slice(t_from=t,t_to=t),min_weight=weight_slider.value)\n",
        "        g_sofar=to_static(dg.time_slice(t_from=0,t_to=t),min_weight=weight_slider.value)\n",
        "        sized=nx.betweenness_centrality(g_sofar)\n",
        "        #pos=nx.spring_layout(g_sofar)\n",
        "        ofn_img=os.path.join(odir,f'net-{str(t).zfill(4)}.png')\n",
        "        title=f'{NOVEL_TITLE_NICE} (t={str(t).zfill(4)})'\n",
        "        try:\n",
        "            drawnet_nx(\n",
        "                g_sofar,\n",
        "                save=True,\n",
        "                ofn=ofn_img,\n",
        "                pos=pos,\n",
        "                size_by=widg_sizeby.value,\n",
        "                color_by=widg_colorby.value,\n",
        "                weight_factor=weight_factor.value,\n",
        "                title=title\n",
        "            )\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "def do_drawnets(*x,**y):\n",
        "    global dg\n",
        "    global ofn_fig_dir\n",
        "    drawnets(dg,odir=ofn_fig_dir)\n",
        "\n",
        "if not os.path.exists(ofn_fig_dir) or not os.listdir(ofn_fig_dir):\n",
        "    res=do_drawnets()\n",
        "\n",
        "button2=widgets.Button(description='Regenerate images')\n",
        "button2.on_click(do_drawnets)\n",
        "button2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajNd0k7PM13Y",
        "cellView": "form"
      },
      "source": [
        "#@title Generate mp4 video from images\n",
        "def make_vid_from_folder(*x,image_folder=ofn_fig_dir,ofn=ofn_mp4,fps=15):\n",
        "    import moviepy.video.io.ImageSequenceClip\n",
        "\n",
        "    image_files = [os.path.join(image_folder,img) for img in sorted(os.listdir(image_folder)) if img.endswith(\".png\")]\n",
        "    clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
        "    clip.write_videofile(ofn)\n",
        "\n",
        "if not os.path.exists(ofn_mp4): make_vid_from_folder()\n",
        "button3=widgets.Button(description='Regenerate Video')\n",
        "button3.on_click(make_vid_from_folder)\n",
        "# display(button3)\n",
        "\n",
        "# show video\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "from base64 import b64encode\n",
        "mp4 = open(ofn_mp4,'rb').read()\n",
        "display(button3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAzKh8aj0n_O",
        "cellView": "form"
      },
      "source": [
        "#@title Show video\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "display(HTML(\"\"\"\n",
        "<video width=666 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sAcA9YO6PwF",
        "cellView": "form"
      },
      "source": [
        "#@title Generate gif from images\n",
        "def make_gif_from_folder(folder=ofn_fig_dir,ofn=ofn_gif):\n",
        "    import imageio\n",
        "    images = []\n",
        "    for fn in sorted(os.listdir(folder)):\n",
        "        if fn.endswith('.png'):\n",
        "            with open(os.path.join(folder,fn),'rb') as f:\n",
        "                images.append(imageio.imread(f))\n",
        "    imageio.mimsave(ofn, images)\n",
        "\n",
        "\n",
        "if not os.path.exists(ofn_gif): make_gif_from_folder()\n",
        "\n",
        "button2=widgets.Button(description='Regenerate GIF')\n",
        "button2.on_click(make_gif_from_folder)\n",
        "display(button2)\n",
        "\n",
        "# show gif?\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from IPython import display\n",
        "from pathlib import Path\n",
        "gifPath = Path(ofn_gif)\n",
        "# Display GIF in Jupyter, CoLab, IPython\n",
        "with open(gifPath,'rb') as f:\n",
        "    display.Image(data=f.read(), format='png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y2GRMvYvZPa"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMBLBppGLDGP",
        "cellView": "form"
      },
      "source": [
        "#@title Zip data\n",
        "PATH_ZIP=os.path.abspath(os.path.join(PATH_NOVEL,'..',NOVEL_TITLE+'.zip'))\n",
        "cmd=f'cd {PATH_NOVEL}/.. && zip -r9 {PATH_ZIP} {NOVEL_TITLE}'\n",
        "!{cmd}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8FykPAAvRTv",
        "cellView": "both"
      },
      "source": [
        "##@title Download zip file\n",
        "def dlzip(): files.download(PATH_ZIP)\n",
        "dlsize=os.path.getsize(path)\n",
        "def human_size(bytes, units=[' bytes','KB','MB','GB','TB', 'PB', 'EB']):\n",
        "    \"\"\" Returns a human readable string representation of bytes \"\"\"\n",
        "    return str(bytes) + units[0] if bytes < 1024 else human_size(bytes>>10, units[1:])\n",
        "dlbutton=widgets.Button(description=f'Download zip file ({human_size(dlsize)})')\n",
        "dlbutton"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bZt4YnUzPRB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}